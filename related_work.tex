\section{Related work (unlocked, I need to skim read the precision papers)}

The previous work primarily focuses on multiresolution and precision
reduction independently and we will discuss both directions
(TODO: JPEG, wavelets is sort of both).


\subsection{Adaptivity in Resolution}
Multiresolution techniques are commonly employed to improve performance or
reduce aliasing (MIPMAPs). Especially popular are approaches that create
multiple level of details such as multiresolution octrees~\cite{multires_octree1999},
AMR meshes~\cite{amr1989}, or sparse grids~\cite{vdb2013, spgrid2014}. In these data structures,
the data can be stored multiple times at different levels created by application of a kernel
(such as averaging). 

For example, Compression-domain Output-sensitive Volume Rendering Architecture (COVRA)~\cite{covra2012}
constructs a level-of-detail pyramid in precomputation stage to reduce memory usage for blocks that
are far from camera. Moreover, authors further compress the blocks of the pyramid to improve the
streaming time, either to GPU or over network. However, this level-of-detail representation increases data size
and may not be desired depending on a task.

Alternatives such as IDX~\cite{idx2001} primarily focus on reordering the data to allow
for faster queries. For example, row-major order is optimal only for slicing
along one axis, but the other two axis have poor cache utilization. In contrast, hilbert
or morton order is not optimal for any axis, but on average it outperforms the row-major
order. Combined with tiling morton order can be highly efficient [CITE texture units] as
it can utilize fast CPU instructions for conversion to xyz index space~\cite{spgrid2014}.
Moreover, the order can be changed such that it becomes hierarchical, thus providing
level-of-detail via subsampling without needing any additional storage. Unfortunately,
the subsampling introduces interpolation issues where commonly used trilinear interpolation
is no longer correct.

Wavelet transform constructs hierarchy of resolution levels by applying function and storing
the result in lower resolution level along with the difference at finer level. Similarly to
data reordering techniques, this transform does not increase the data size. Moreover, since
the function support increases as the resolution decreases, the interpolation is well defined
compared to the data formats based on subsampling. The adaptivity in resolution can be achieved
by tiling the wavelet coefficients of individual subbands.

For example, Visualization and Analysis Platform for Ocean, Atmosphere, and Solar Researchers
(VAPOR)~\cite{multires_toolkit2003, vapor2007} incorporates a multiresolution file
format to allow data analysis on commodity hardware and stores individual tiles in
separate files to allow loading of the region of interest.
However, the authors only leverage the resolution control without exploring the precision axis
(TODO: at least it seems from looking at those papers, I did not check their code) which
we will discuss in the next subsection.


\subsection{Adaptivity in Precision}
Reducing precision of the samples is primarily used in data compression techniques. 

SPIHT~\cite{spiht1996}


SBHP~\cite{sbhp2000}

JPEG2000~\cite{jpeg2001}


The other major research focus is precision reduction to compress the data. Quantization and
truncation.



The state-of-the-art techniques such as ZFP~\cite{zfp2014} exploit the in small $4^3$ blocks
and thus allow localized decompression. Moreover, ZFP supports fixed-rate compression which
is necessary for random access to the data. The fast transform and caching allows it to
achieve high throughput. (Peter should write this section)
Fixed-rate and fixed-precision modes. Not able to adapt rate spatially.

JPEG2000 can be used to store floating point data~\cite{woodring2011}. Since JPEG2000 is limited
to integer data, authors perform uniform scalar quantization to convert floating point data to integer
form. Even though JPEG2000 support to vary both resolution and precision the paper does not explore
the two axis and focuses only on bit rate (TODO: is bit rate tied only to precision or also resolution?).


SPECK~\cite{speck2004}



Volume rendering stuff
Compression domain volume rendering~\cite{compression_domain2003}

Transfer function adaptive decompression~\cite{tf_decompression2004}

Transform Coding for HW-accel DVR~\cite{hw_dvr2007}

Tensor appriximation for DVR~\cite{tensor_dvr2015}



