\section{Related work}

Techniques that reduce data in resolution typically build a tree-shape hierarchy over the data. A
very common scheme to genearte such a hierarchy is to construct low-resolution copies of the data
from higher-resolution ones through filtering and subsampling. Examples include Gaussian and
Laplacian pyramids~\cite{laplacian-pyramid},
mipmaps~\cite{multires_octree1999,interactive-exploration-ct-scans}. Often times, the data is stored
in blocks on each resolution level. To save bandwidth, low-resolution blocks can be streamed during
rendering, if the points being queried project to less than a pixel on screen. However, these methods
increase storage requirements, making them unsuitable for very large data.

Recent multi-resolution techniques save storage by adapting to the data in such a way that different
regions of the data are stored in different resolutions, depending on how ``homogeneous'' the region
is. Fast-varying regions are stored at higher resolution. A very popular approach is sparse voxel
octrees (SVO), pioneered by Crassin \etal~\cite{gigavoxels} and Gobbetti \etal~\cite{Gobbetti2008},
and variations of which are found in~\cite{Fogal-2013-RayGuided,visualization-driven}. Sparsity
comes from the fact that smooth-varying regions are stored at coarser octree levels, which
significantly reduces storage. During rendering, blocks of samples are streamed from an appropriate
resolution, determined by how far the queried samples are from the eye/camera. Beyer
\etal~\cite{large‚Äêscale-volume} gives a comprehensive overview of this family of techniques.

Other trees such as B+ tree~\cite{vdb2013} and kd-tree~\cite{fogal-kdtree} can also be used in lieu
of octrees to build a sparse hierarchy. Alternatively, space-filling curves such as the hierarhical
Z curve~\cite{idx2001} can be used to reorder data samples to form a hierarchy without any filtering
steps or redundant samples, as low-resolution levels are constructed via subsampling. Unfortunately,
subsampling can introduce heavy aliasing artifacts.

\duong{continue from here}
A sparse multiresolution hierarchy offers level-of-detail access, which reduces bandwidth. 

wavelets~\cite{treib,multires_toolkit2003,vapor2007,woodring2011}.

For example, the Compression-domain Output-sensitive Volume Rendering Architecture
(COVRA)~\cite{covra2012} constructs a level-of-detail pyramid in a precomputation stage to reduce
memory usage for blocks that are far from the viewpoint. Moreover, COVRA further compresses the
blocks of the pyramid to reduce the data transfer time, either to the GPU or over a network.
However, this redundant level-of-detail representation increases data size, which may be undesirable
for some tasks.

wavelets:
~\cite{treib}
~\cite{multires-framework}
~\cite{compression-domain-volume-rendering}
~\cite{interactive-rendering-large-volume}
~\cite{rapid-compression-volume}
~\cite{survey-multires}
~\cite{multires_toolkit2003}
~\cite{wavelet-compression-interactive-vis}

resolution
~\cite{multires-volume-rendering} (wavelet, level of detail)
~\cite{in-situ-sampling-particle}

tensor:
~\cite{tensor_dvr2015}
~\cite{multiscale-tensor}
~\cite{tamresh}

Octrees:
~\cite{sph-octree} (octree + wavelet compression)

Other trees:

Error analysis:
~\cite{evaluating-compression-climate}
~\cite{compression_sim2013}
~\cite{statistical-volume-quality}
~\cite{evaluating-efficacy-wavelet}
~\cite{topology-verification-isosurface}
~\cite{verifiable-isosurface}
~\cite{verifying-volume-rendering}
~\cite{statistical-volume-quality}

vector quantization:
~\cite{vq1992}
~\cite{hw_dvr2007} (VQ on transfrom domain)
~\cite{compression_domain2003} (VQ after Haar-like transform)
~\cite{covra2012} octrees of bricks with sparse representations

error-guided: 
~\cite{tf_decompression2004} (based on transfer function)

~\cite{spgrid2014}

surveys:
~\cite{state-of-the-art-compressed-volume} (compressed volume rendering)
~\cite{li2018} data reduction techniques

compression:
~\cite{isabela}
~\cite{fpzip}
~\cite{sz}
~\cite{zfp2014}

precision:
~\cite{ezw}
~\cite{spiht1996}
~\cite{mloc}
~\cite{sbhp2000}
~\cite{jpeg2001}

The wavelet transform constructs a hierarchy of resolution levels via low and high bandpass filters.
The transform is recursively applied to the lower-resolution band, resulting in a hierarchy of
``details'' at varying resolution. One benefit of wavelets over redundant representations like
Laplacian pyramids is that the wavelet transform is merely a change of basis that like reordering
techniques does not increase the data size. Another benefit over AMR and other tree-like techniques
is that the wavelet basis functions are defined everywhere in space, requiring no special
interpolation rules when given some arbitrary subset of wavelet coefficients and basis functions.
One disadvantage of the wavelet transform is non-constant time random access cost, though
acceleration structures have been proposed to speed up local queries~\cite{weiss}.

Spatial adaptivity in resolution can be achieved by tiling the wavelet coefficients of individual
subbands. For example, the Visualization and Analysis Platform for Ocean, Atmosphere, and Solar
Researchers (VAPOR) toolkit~\cite{multires_toolkit2003, vapor2007} incorporates a multiresolution
file format based on a wavelets to allow data analysis on commodity hardware, and stores individual
tiles in separate files to allow loading of the region of interest. However, the authors only
leverage the resolution control without exploring the precision axis, which can potentially further
reduce data transfer.

Reducing precision of the samples is primarily used in data compression techniques. 

The SPIHT~\cite{spiht1996} wavelet coefficient coding algorithm hierarchically partitions sets of
spatially related wavelet coefficients, exploiting the property that ``parent'' coefficients are
often larger in magnitude than ``child'' coefficients. This format allows regions to be
progressively refined in precision by coding more significant bitplanes before less significant
ones.

SBHP~\cite{sbhp2000}
JPEG2000~\cite{jpeg2001}
by bit plane streams~\cite{compression_techniques1991} (this is what SPIHT paper cites).
by magnitude streams~\cite{image_compression1992}
\peter{I'm not familiar with these last two papers.  Instead, point out that
SPIHT improves on embedded zerotree coding~\cite{ezw}.}

The other major research focus is precision reduction to compress the data. Quantization and
truncation.

\peter{Discuss scalar~\cite{sqe} vs. vector quantization~\cite{hvq}. SZ performs residual scalar
quantization~\cite{sz}. \cite{fpzip} truncates floats, which can be seen as nonuniform scalar
quantization.}

\newcommand{\zfp}{\textsc{zfp}\xspace}
Block transform-based techniques such as \zfp~\cite{zfp2014} partition the domain---a structured
grid---into small (e.g., $4 \times 4 \times 4$) independent blocks and thus allow for localized
decompression. Moreover, \zfp supports fixed-rate compression, which facilitates random access to
the data. Its fast transform and caching of decompressed data allows it to achieve not only high
throughput decompression~\cite{hvq}, but also fast inline compression. Extensions of \zfp allow it
to vary either the bit rate or precision spatially over the domain, albeit at fixed resolution.
\peter{Not sure if we want to cite my ARC poster on this: https://computation.llnl.gov/sites/default/files/public//llnl-post-728998.pdf}

\peter{Should the following go in a section on ``hybrid'' precision and resolution techniques?}

Woodring \etal~\cite{woodring2011} use the JPEG2000 image format to store floating point data.
Since most JPEG2000 implementations are limited to integer data, the authors apply uniform scalar
quantization to convert floating point data to integer form. Even though JPEG2000 supports varying
both resolution and precision, the authors do not explore this capability but focus only on setting
a bit rate.

\peter{Another wavelet paper relevant to VIS: \cite{treib}}.

Transfer function adaptive decompression~\cite{tf_decompression2004}

Transform Coding for HW-accel DVR~\cite{hw_dvr2007}

Tensor approximation for DVR~\cite{tensor_dvr2015}
\peter{This can be both resolution and precision.}

\peter{We might want to cite~\cite{codar} and~\cite{li} for surveys on data reduction.}
