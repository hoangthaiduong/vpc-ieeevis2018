@article{hierarchical1984,
 author = {Samet, Hanan},
 title = {The Quadtree and Related Hierarchical Data Structures},
 journal = {ACM Comput. Surv.},
 issue_date = {June 1984},
 volume = {16},
 number = {2},
 month = jun,
 year = {1984},
 issn = {0360-0300},
 pages = {187--260},
 numpages = {74},
 url = {http://doi.acm.org/10.1145/356924.356930},
 doi = {10.1145/356924.356930},
 acmid = {356930},
 publisher = {ACM},
 address = {New York, NY, USA},
}


@article{amr1989,
 author = {Berger, M. J. and Colella, P.},
 title = {Local Adaptive Mesh Refinement for Shock Hydrodynamics},
 journal = {J. Comput. Phys.},
 issue_date = {May, 1989},
 volume = {82},
 number = {1},
 month = may,
 year = {1989},
 issn = {0021-9991},
 pages = {64--84},
 numpages = {21},
 url = {http://dx.doi.org/10.1016/0021-9991(89)90035-1},
 doi = {10.1016/0021-9991(89)90035-1},
 acmid = {1718335},
 publisher = {Academic Press Professional, Inc.},
 address = {San Diego, CA, USA},
} 


@book{compression_techniques1991,
 author = {Rabbani, Majid and Jones, Paul W.},
 title = {Digital Image Compression Techniques},
 year = {1991},
 isbn = {0819406481},
 edition = {1st},
 publisher = {Society of Photo-Optical Instrumentation Engineers (SPIE)},
 address = {Bellingham, WA, USA},
}


@article{histogram_intersection1991,
author="Swain, Michael J.
and Ballard, Dana H.",
title="Color indexing",
journal="International Journal of Computer Vision",
year="1991",
month="Nov",
day="01",
volume="7",
number="1",
pages="11--32",
abstract="Computer vision is embracing a new research focus in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, realistic environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the location of a known object. Color can be successfully used for both tasks.",
issn="1573-1405",
doi="10.1007/BF00130487",
url="https://doi.org/10.1007/BF00130487"
}


@article{image_compression1992,
 author = {R.A. DeVore and B. Jawerth and B.J. Lucier},
 title = {Image compression through wavelet transform coding},
 journal = {IEEE Trans. Inform. Theory},
 volume = {38},
 month = march,
 year = {1992},
 pages = {719--746},
} 


@inproceedings{vq1992,
 author = {Ning, Paul and Hesselink, Lambertus},
 title = {Vector Quantization for Volume Rendering},
 booktitle = {Proceedings of the 1992 Workshop on Volume Visualization},
 series = {VVS '92},
 year = {1992},
 isbn = {0-89791-527-5},
 location = {Boston, Massachusetts, USA},
 pages = {69--74},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/147130.147152},
 doi = {10.1145/147130.147152},
 acmid = {147152},
 publisher = {ACM},
 address = {New York, NY, USA},
} 


@ARTICLE{spiht1996,
author={A. Said and W. A. Pearlman},
journal={IEEE Transactions on Circuits and Systems for Video Technology},
title={A new, fast, and efficient image codec based on set partitioning in hierarchical trees},
year={1996},
volume={6},
number={3},
pages={243-250},
keywords={arithmetic codes;codecs;data compression;entropy codes;image coding;image reconstruction;transform coding;trees (mathematics);wavelet transforms;arithmetic code;decoding;decoding algorithm;embedded zerotree wavelet coding;entropy coding;file sizes;image codec;image coding;image compression;image reconstruction;image wavelet transform;ordered bit plane transmission;partial ordering;performance;self-similarity;set partitioning in hierarchical trees;set partitioning sorting algorithm;Codecs;Decoding;Image coding;Image reconstruction;Partitioning algorithms;Performance loss;Signal processing;Signal processing algorithms;Sorting;Wavelet transforms},
doi={10.1109/76.499834},
ISSN={1051-8215},
month={Jun},}


@INPROCEEDINGS{emd1998,
author={Y. Rubner and C. Tomasi and L. J. Guibas},
booktitle={Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
title={A metric for distributions with applications to image databases},
year={1998},
volume={},
number={},
pages={59-66},
keywords={image colour analysis;image texture;visual databases;color;distributions;easy-to-compute lower bounds;image databases;linear optimization;multi-dimensional scaling displays;partial matching;texture;transportation problem;Application software;Computer displays;Computer science;Frequency;Geoscience;Histograms;Image databases;Image retrieval;Navigation;Psychology},
doi={10.1109/ICCV.1998.710701},
ISSN={},
month={Jan},}


@inproceedings{multires_octree1999,
 author = {LaMar, Eric and Hamann, Bernd and Joy, Kenneth I.},
 title = {Multiresolution Techniques for Interactive Texture-based Volume Visualization},
 booktitle = {Proceedings of the Conference on Visualization '99: Celebrating Ten Years},
 series = {VIS '99},
 year = {1999},
 isbn = {0-7803-5897-X},
 location = {San Francisco, California, USA},
 pages = {355--361},
 numpages = {7},
 url = {http://dl.acm.org/citation.cfm?id=319351.319432},
 acmid = {319432},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords = {hardware texture, multiresolution rendering, volume visualization},
} 


@INPROCEEDINGS{sbhp2000,
author={C. Chrysafis and A. Said and A. Drukarev and A. Islam and W. A. Pearlman},
booktitle={2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)},
title={SBHP-a low complexity wavelet coder},
year={2000},
volume={6},
number={},
pages={2035-2038 vol.4},
keywords={code standards;computational complexity;data compression;entropy codes;image coding;transform coding;wavelet transforms;JPEG2000 image compression standard framework;SBHP;algorithm;compression performance;embedded coding;entropy coding;low complexity wavelet coder;low-complexity entropy coder;nonembedded coding;subband-block hierarchical partitioning;verification model;wavelet coefficients;Algorithm design and analysis;Code standards;Entropy coding;Image coding;Partitioning algorithms;Performance loss;Testing;Transform coding;Virtual manufacturing;Wavelet coefficients},
doi={10.1109/ICASSP.2000.859233},
ISSN={1520-6149},
month={},}


@ARTICLE{jpeg2001,
author={A. Skodras and C. Christopoulos and T. Ebrahimi},
journal={IEEE Signal Processing Magazine},
title={The JPEG 2000 still image compression standard},
year={2001},
volume={18},
number={5},
pages={36-58},
keywords={ISO standards;code standards;data compression;entropy codes;image coding;quantisation (signal);reviews;standardisation;telecommunication standards;transform coding;wavelet transforms;ISO/IEC;JPEG 2000 still image compression standard;Part I standard;entropy coding;error resilience;file format;image tiling;international standard;multicomponent transformations;performance comparisons;quantization;region-of-interest coding;scalability;standardization committee;visual weighting;wavelet transforms;Entropy coding;IEC standards;ISO standards;Image coding;Quantization;Resilience;Scalability;Standardization;Transform coding;Wavelet transforms},
doi={10.1109/79.952804},
ISSN={1053-5888},
month={Sep},}


@INPROCEEDINGS{idx2001,
author={V. Pascucci and R. J. Frank},
booktitle={Supercomputing, ACM/IEEE 2001 Conference},
title={Global Static Indexing for Real-Time Exploration of Very Large Regular Grids},
year={2001},
volume={},
number={},
pages={45-45},
keywords={Cache memory;Computer displays;Data visualization;Degradation;Grid computing;Indexing;Laboratories;Multiprocessing systems;Portable computers;Random access memory},
doi={10.1145/582034.582036},
ISSN={},
month={Nov},}


@INPROCEEDINGS{compression_domain2003,
author={J. Schneider and R. Westermann},
booktitle={IEEE Visualization, 2003. VIS 2003.},
title={Compression domain volume rendering},
year={2003},
volume={},
number={},
pages={293-300},
keywords={computer graphic equipment;image texture;rendering (computer graphics);vector quantisation;CPU;GPU;commodity graphics hardware;compression domain volume rendering;data transfer;gigabyte data sets;graphics processing unit;hierarchical quantization;multiresolution covariance analysis;programmable hardware;real-time rendering;temporal coherence;texture mapping hardware;texture memory;time-varying volumetric data set;vector quantization;Central Processing Unit;Computer graphics;Data visualization;Decoding;Encoding;Hardware;Large-scale systems;Rendering (computer graphics);Shock waves;Vector quantization},
doi={10.1109/VISUAL.2003.1250385},
ISSN={},
month={Oct},}

@inproceedings{multires_toolkit2003,
author = {Clyne, John},
pages = {152-157},
title = {The multiresolution toolkit: Progressive access for regular gridded data},
booktitle = {Proc. Visualization, Imaging, and Image Processing},
year = {2003},
}


@INPROCEEDINGS{tf_decompression2004,
author={P. Ljung and C. Lundstrom and A. Ynnerman and K. Museth},
booktitle={2004 IEEE Symposium on Volume Visualization and Graphics},
title={Transfer function based adaptive decompression for volume rendering of large medical data sets},
year={2004},
volume={},
number={},
pages={25-32},
keywords={biomedical imaging;data compression;image coding;medical computing;rendering (computer graphics);transfer functions;wavelet transforms;compressed wavelet transformed blocks;image decompression;image quality;image rendering;medical imaging;medical transfer functions;multiresolution data representation;standard volumetric data sets;volume compression;volume rendering;Bandwidth;Biomedical imaging;Computed tomography;Data visualization;Image coding;Image resolution;Medical diagnostic imaging;Pipelines;Rendering (computer graphics);Transfer functions;Adaptive decompression;Image quality measures;Medical imaging;Multiresolution;Transfer function;Volume compression;Volume rendering;Wavelet transform},
doi={10.1109/SVVG.2004.14},
ISSN={},
month={Oct},}


@ARTICLE{speck2004,
author={W. A. Pearlman and A. Islam and N. Nagaraj and A. Said},
journal={IEEE Transactions on Circuits and Systems for Video Technology},
title={Efficient, low-complexity image coding with a set-partitioning embedded block coder},
year={2004},
volume={14},
number={11},
pages={1219-1235},
keywords={block codes;computational complexity;data compression;discrete cosine transforms;entropy codes;image coding;image colour analysis;optimisation;pattern clustering;transform coding;trees (mathematics);wavelet transforms;color image coding;discrete cosine transform;dyadic image transform;energy clustering;entropy coding;hierarchical trees;image wavelet transform coding algorithm;lossless coding;low-complexity image coding;rate distortion optimization;recursive set-partitioning embedded block coder;reversible coding;sorting mechanism;wavelet packets;Clustering algorithms;Color;Discrete cosine transforms;Discrete wavelet transforms;Frequency;Image coding;Partitioning algorithms;Transform coding;Wavelet coefficients;Wavelet packets;Color image coding;embedded coding;entropy coding;hierarchical coding;image coding;lossless coding;wavelet coding},
doi={10.1109/TCSVT.2004.835150},
ISSN={1051-8215},
month={Nov},}


@article{vapor2007,
  author={John Clyne and Pablo Mininni and Alan Norton and Mark Rast},
  title={Interactive desktop analysis of high resolution simulations: application to turbulent plume dynamics and current sheet formation},
  journal={New Journal of Physics},
  volume={9},
  number={8},
  pages={301},
  url={http://stacks.iop.org/1367-2630/9/i=8/a=301},
  year={2007},
}


@ARTICLE{hw_dvr2007,
author={N. Fout and K. L. Ma},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Transform Coding for Hardware-accelerated Volume Rendering},
year={2007},
volume={13},
number={6},
pages={1600-1607},
keywords={computer graphic equipment;data compression;real-time systems;rendering (computer graphics);transform coding;GPU;compression quality;decompression;dequantization;graphics memory;hardware-accelerated volume rendering;inverse transform;large volume data sets;real-time volume rendering;software volume rendering;transform coding;volumetric compression;Data visualization;Decoding;Encoding;Graphics;Hardware;Pipelines;Production;Rendering (computer graphics);Resource management;Transform coding;Compressed Volume Rendering;Hardware-accelerated Volume Rendering;Transform Coding;Volume Compression},
doi={10.1109/TVCG.2007.70516},
ISSN={1077-2626},
month={Nov},}


@INPROCEEDINGS{woodring2011,
author={J. Woodring and S. Mniszewski and C. Brislawn and D. DeMarle and J. Ahrens},
booktitle={2011 IEEE Symposium on Large Data Analysis and Visualization},
title={Revisiting wavelet compression for large-scale climate data using JPEG 2000 and ensuring data precision},
year={2011},
volume={},
number={},
pages={31-38},
keywords={data analysis;data compression;data visualisation;electronic data interchange;environmental science computing;expert systems;production engineering computing;wavelet transforms;JPEG 2000;data analysis;data compression community;data precision;data quality;data transfer;data visualization;domain expert;large-scale climate data;large-scale data reading;large-scale data size;large-scale data writing;parallel ocean program data;production scientific computing;quality metric;remotely compressed POP data;signal processing;standard-based method;wavelet compression;Bit rate;Data visualization;Image coding;Quantization;Transform coding;Wavelet transforms},
doi={10.1109/LDAV.2011.6092314},
ISSN={},
month={Oct},}


@article {covra2012,
author = {Gobbetti, Enrico and Iglesias Guitián, José Antonio and Marton, Fabio},
title = {COVRA: A compression-domain output-sensitive volume rendering architecture based on a sparse representation of voxel blocks},
journal = {Computer Graphics Forum},
volume = {31},
number = {3pt4},
publisher = {Blackwell Publishing Ltd},
issn = {1467-8659},
url = {http://dx.doi.org/10.1111/j.1467-8659.2012.03124.x},
doi = {10.1111/j.1467-8659.2012.03124.x},
pages = {1315--1324},
keywords = {Computer Graphics [I.3.3]: Picture/Image Generation—, Computer Graphics [I.3.7]: Three-dimensional graphics and realism—, Coding and Information Theory [E.4]: Data compaction and compression—, Compression (Coding) [I.4.2]: Approximate methods—},
year = {2012},
}


@article{vdb2013,
 author = {Museth, Ken},
 title = {VDB: High-resolution Sparse Volumes with Dynamic Topology},
 journal = {ACM Trans. Graph.},
 issue_date = {June 2013},
 volume = {32},
 number = {3},
 month = jul,
 year = {2013},
 issn = {0730-0301},
 pages = {27:1--27:22},
 articleno = {27},
 numpages = {22},
 url = {http://doi.acm.org/10.1145/2487228.2487235},
 doi = {10.1145/2487228.2487235},
 acmid = {2487235},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Volumes, fluid animation, implicit surfaces, level sets},
}


@inproceedings{compression_sim2013,
  author    = {Daniel E. Laney and
               Steven Langer and
               Christopher Weber and
               Peter Lindstrom and
               Al Wegener},
  title     = {Assessing the effects of data compression in simulations using physically
               motivated metrics},
  booktitle = {International Conference for High Performance Computing, Networking,
               Storage and Analysis, SC'13, Denver, CO, {USA} - November 17 - 21,
               2013},
  pages     = {76:1--76:12},
  year      = {2013},
  url       = {http://doi.acm.org/10.1145/2503210.2503283},
  doi       = {10.1145/2503210.2503283},
  timestamp = {Mon, 05 Jun 2017 12:39:52 +0200},
  biburl    = {http://dblp.org/rec/bib/conf/sc/LaneyLWLW13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{spgrid2014,
 author = {Setaluri, Rajsekhar and Aanjaneya, Mridul and Bauer, Sean and Sifakis, Eftychios},
 title = {SPGrid: A Sparse Paged Grid Structure Applied to Adaptive Smoke Simulation},
 journal = {ACM Trans. Graph.},
 issue_date = {November 2014},
 volume = {33},
 number = {6},
 month = nov,
 year = {2014},
 issn = {0730-0301},
 pages = {205:1--205:12},
 articleno = {205},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2661229.2661269},
 doi = {10.1145/2661229.2661269},
 acmid = {2661269},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptive discretizations, fluid simulation, sparse grids},
}


@ARTICLE{zfp2014,
author={P. Lindstrom},
journal={IEEE Transactions on Visualization and Computer Graphics},
title={Fixed-Rate Compressed Floating-Point Arrays},
year={2014},
volume={20},
number={12},
pages={2674-2683},
keywords={computer graphics;data compression;data visualisation;embedded systems;floating point arithmetic;graphics processing units;random-access storage;storage management;bit rate selection;data access;data visualization;embedded coding;fixed-point arithmetic operations;fixed-precision values;fixed-rate compressed floating-point arrays;fixed-rate texture compression methods;floating-point data;graphics hardware;hardware implementation;lossy compression;memory management;near-lossless compression scheme;numerical simulation;orthogonal block transform;per-block bit stream;quantitative data analysis;read and write random access;scientific applications;software write-back cache;variable-length bit stream;Bandwidth allocation;Computational modeling;Data visualization;Encoding;Floating-point arithmetic;Image coding;Data compression;embedded coding;floating-point arrays;orthogonal block transform},
doi={10.1109/TVCG.2014.2346458},
ISSN={1077-2626},
month={Dec},}


@article{tensor_dvr2015,
 author = {Ballester-Ripoll, Rafael and Suter, Susanne K. and Pajarola, Renato},
 title = {Analysis of Tensor Approximation for Compression-domain Volume Visualization},
 journal = {Comput. Graph.},
 issue_date = {April 2015},
 volume = {47},
 number = {C},
 month = apr,
 year = {2015},
 issn = {0097-8493},
 pages = {34--47},
 numpages = {14},
 url = {http://dx.doi.org/10.1016/j.cag.2014.10.002},
 doi = {10.1016/j.cag.2014.10.002},
 acmid = {2902848},
 publisher = {Pergamon Press, Inc.},
 address = {Elmsford, NY, USA},
 keywords = {Canonical decomposition, Higher-order decompositions, Tensor approximation, Tensor rank truncation, Tucker decomposition, Volume visualization},
}

@article{fpzip,
 author = {Lindstrom, Peter and Isenburg, Martin},
 title = {Fast and Efficient Compression of Floating-Point Data},
 journal = {IEEE Transactions on Visualization and Computer Graphics},
 issue_date = {September 2006},
 volume = {12},
 number = {5},
 month = sep,
 year = {2006},
 issn = {1077-2626},
 pages = {1245--1250},
 numpages = {6},
 url = {http://dx.doi.org/10.1109/TVCG.2006.143},
 doi = {10.1109/TVCG.2006.143},
 acmid = {1187859},
 publisher = {IEEE Educational Activities Department},
 address = {Piscataway, NJ, USA},
 keywords = {High throughput, High throughput, lossless compression, file compaction for I/O efficiency, fast entropy coding, range coder, predictive coding, large scale simulation and visualization., fast entropy coding, file compaction for I/O efficiency, large scale simulation and visualization., lossless compression, predictive coding, range coder},
} 

@INPROCEEDINGS{sz, 
	author={D. Tao and S. Di and Z. Chen and F. Cappello}, 
	booktitle={2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
	title={Significantly Improving Lossy Compression for Scientific Data Sets Based on Multidimensional Prediction and Error-Controlled Quantization}, 
	year={2017}, 
	volume={}, 
	number={}, 
	pages={1129-1139}, 
	keywords={data compression;parallel processing;HPC applications;adaptive error-controlled quantization encoder;error-controlled lossy compression algorithm;multidimensional prediction;multilayer prediction formulas;normalized root mean squared error;scientific data sets;Adaptation models;Compression algorithms;Data models;Encoding;Measurement;Predictive models;Quantization (signal)}, 
	doi={10.1109/IPDPS.2017.115}, 
	ISSN={}, 
	month={May},
}

@INPROCEEDINGS{hvg, 
	author={J. Schneider and R. Westermann}, 
	booktitle={IEEE Visualization, 2003. VIS 2003.}, 
	title={Compression domain volume rendering}, 
	year={2003}, 
	volume={}, 
	number={}, 
	pages={293-300}, 
	keywords={computer graphic equipment;image texture;rendering (computer graphics);vector quantisation;CPU;GPU;commodity graphics hardware;compression domain volume rendering;data transfer;gigabyte data sets;graphics processing unit;hierarchical quantization;multiresolution covariance analysis;programmable hardware;real-time rendering;temporal coherence;texture mapping hardware;texture memory;time-varying volumetric data set;vector quantization;Central Processing Unit;Computer graphics;Data visualization;Decoding;Encoding;Hardware;Large-scale systems;Rendering (computer graphics);Shock waves;Vector quantization}, 
	doi={10.1109/VISUAL.2003.1250385}, 
	ISSN={}, 
	month={Oct},
}

@InProceedings{isabela,
	author="Lakshminarasimhan, Sriram
	and Shah, Neil
	and Ethier, Stephane
	and Klasky, Scott
	and Latham, Rob
	and Ross, Rob
	and Samatova, Nagiza F.",
	editor="Jeannot, Emmanuel
	and Namyst, Raymond
	and Roman, Jean",
	title="Compressing the Incompressible with ISABELA: In-situ Reduction of Spatio-temporal Data",
	booktitle="Euro-Par 2011 Parallel Processing",
	year="2011",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="366--379",
	abstract="Modern large-scale scientific simulations running on HPC systems generate data in the order of terabytes during a single run. To lessen the I/O load during a simulation run, scientists are forced to capture data infrequently, thereby making data collection an inherently lossy process. Yet, lossless compression techniques are hardly suitable for scientific data due to its inherently random nature; for the applications used here, they offer less than 10{\%} compression rate. They also impose significant overhead during decompression, making them unsuitable for data analysis and visualization that require repeated data access.",
	isbn="978-3-642-23400-2"
}

@inproceedings{sqe,
	author = {Iverson, Jeremy and Kamath, Chandrika and Karypis, George},
	title = {Fast and Effective Lossy Compression Algorithms for Scientific Datasets},
	booktitle = {Proceedings of the 18th International Conference on Parallel Processing},
	series = {Euro-Par'12},
	year = {2012},
	isbn = {978-3-642-32819-0},
	location = {Rhodes Island, Greece},
	pages = {843--856},
	numpages = {14},
	url = {http://dx.doi.org/10.1007/978-3-642-32820-6_83},
	doi = {10.1007/978-3-642-32820-6_83},
	acmid = {2402519},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
} 

@InProceedings{codar,
	author="Foster, Ian
	and Ainsworth, Mark
	and Allen, Bryce
	and Bessac, Julie
	and Cappello, Franck
	and Choi, Jong Youl
	and Constantinescu, Emil
	and Davis, Philip E.
	and Di, Sheng
	and Di, Wendy
	and Guo, Hanqi
	and Klasky, Scott
	and Van Dam, Kerstin Kleese
	and Kurc, Tahsin
	and Liu, Qing
	and Malik, Abid
	and Mehta, Kshitij
	and Mueller, Klaus
	and Munson, Todd
	and Ostouchov, George
	and Parashar, Manish
	and Peterka, Tom
	and Pouchard, Line
	and Tao, Dingwen
	and Tugluk, Ozan
	and Wild, Stefan
	and Wolf, Matthew
	and Wozniak, Justin M.
	and Xu, Wei
	and Yoo, Shinjae",
	editor="Rivera, Francisco F.
	and Pena, Tom{\'a}s F.
	and Cabaleiro, Jos{\'e} C.",
	title="Computing Just What You Need: Online Data Analysis and Reduction at Extreme Scales",
	booktitle="Euro-Par 2017: Parallel Processing",
	year="2017",
	publisher="Springer International Publishing",
	address="Cham",
	pages="3--19",
	abstract="A growing disparity between supercomputer computation speeds and I/O rates makes it increasingly infeasible for applications to save all results for offline analysis. Instead, applications must analyze and reduce data online so as to output only those results needed to answer target scientific question(s). This change in focus complicates application and experiment design and introduces algorithmic, implementation, and programming model challenges that are unfamiliar to many scientists and that have major implications for the design of various elements of supercomputer systems. We review these challenges and describe methods and tools that we are developing to enable experimental exploration of algorithmic, software, and system design alternatives.",
	isbn="978-3-319-64203-1"
}



@article{li2018,
  title = "Data Reduction Techniques for Scientific Visualization and Data Analysis",
  url = "https://pdfs.semanticscholar.org/e555/db81c878deb01f0e8003bc90a30898e3d518.pdf",
  note = "CGF submission in review?"
}

@ARTICLE{laplacian-pyramid, 
	author={P. Burt and E. Adelson}, 
	journal={IEEE Transactions on Communications}, 
	title={The Laplacian Pyramid as a Compact Image Code}, 
	year={1983}, 
	volume={31}, 
	number={4}, 
	pages={532-540}, 
	keywords={Image coding;Data compression;Data structures;Entropy;Frequency;Image coding;Image sampling;Laplace equations;Low pass filters;Pixel;Shape}, 
	doi={10.1109/TCOM.1983.1095851}, 
	ISSN={0090-6778}, 
	month={Apr},
}

@ARTICLE{weiss, 
	author={K. Weiss and P. Lindstrom}, 
	journal={IEEE Transactions on Visualization and Computer Graphics}, 
	title={Adaptive Multilinear Tensor Product Wavelets}, 
	year={2016}, 
	volume={22}, 
	number={1}, 
	pages={985-994}, 
	keywords={data visualisation;interpolation;inverse transforms;mesh generation;octrees;piecewise linear techniques;quadtrees;rendering (computer graphics);splines (mathematics);tensors;adaptive mesh elements;adaptive multilinear tensor product wavelets;adaptive nonconforming quadtree mesh;adaptive regular refinement;crack-free quadtree mesh;direct volume rendering;foundational visualization techniques;globally continuous functions;inverse wavelet transform;isosurfacing;linear B-splines;multilinear cells;nonzero wavelet coefficients;octree mesh;piecewise multilinear interpolation;texture mapping;Interpolation;Octrees;Splines (mathematics);Tensile stress;Wavelet domain;Wavelet transforms;Multilinear interpolation;adaptive wavelets;continuous reconstruction;multiresolution models;octrees}, 
	doi={10.1109/TVCG.2015.2467412}, 
	ISSN={1077-2626}, 
	month={Jan},
}

@ARTICLE{ezw, 
	author={J. M. Shapiro}, 
	journal={IEEE Transactions on Signal Processing}, 
	title={Embedded image coding using zerotrees of wavelet coefficients}, 
	year={1993}, 
	volume={41}, 
	number={12}, 
	pages={3445-3462}, 
	keywords={binary sequences;codecs;data compression;image coding;trees (mathematics);video equipment;wavelet transforms;EZW;adaptive arithmetic coding;binary decisions sequence;bit stream;discrete wavelet transform;embedded zerotree wavelet algorithm;entropy-coded successive-approximation quantization;fully embedded code;hierarchical subband decomposition;image compression algorithm;self-similarity;target distortion metric;target rate;universal lossless data compression;wavelet coefficients;Bit rate;Compression algorithms;Decoding;Discrete wavelet transforms;Image coding;Quantization;Rate distortion theory;Streaming media;Testing;Wavelet coefficients}, 
	doi={10.1109/78.258085}, 
	ISSN={1053-587X}, 
	month={Dec},
}

@ARTICLE{treib, 
	author={M. Treib and K. Bürger and F. Reichl and C. Meneveau and A. Szalay and R. Westermann}, 
	journal={IEEE Transactions on Visualization and Computer Graphics}, 
	title={Turbulence Visualization at the Terascale on Desktop PCs}, 
	year={2012}, 
	volume={18}, 
	number={12}, 
	pages={2169-2177}, 
	keywords={computational fluid dynamics;data visualisation;encoding;entropy;graphics processing units;ray tracing;turbulence;GPU memory;GPU system;bandwidth capacities;brick-based volume ray-casting;compressed flow field representation;desktop computers;entropy encoding;feature-based turbulence visualization;interactive selection;large-scale turbulent motions;memory capacities;run-length;simultaneous visualization;small-scale turbulent motions;spatio-temporal resolution;terascale on desktop PCs;turbulence properties;turbulence small-scale structure;unsteady turbulence simulations;velocity gradient tensor;visually guided exploration;wavelet-based compression scheme;Data visualization;Encoding;Graphics processing unit;Memory management;Rendering (computer graphics);Tensile stress;Vectors;Visualization system and toolkit design;data compression;data streaming;vector fields;volume rendering}, 
	doi={10.1109/TVCG.2012.274}, 
	ISSN={1077-2626}, 
	month={Dec},
}
