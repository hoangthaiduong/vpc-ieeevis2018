%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Bhatia, Harsh at 2018-03-24 14:57:55 -0700 


%% Saved with string encoding Unicode (UTF-8) 



@article{doi:10.1177/1094342018762036,
	Abstract = { Checkpoint restart plays an important role in high-performance computing (HPC) applications, allowing simulation runtime to extend beyond a single job allocation and facilitating recovery from hardware failure. Yet, as machines grow in size and in complexity, traditional approaches to checkpoint restart are becoming prohibitive. Current methods store a subset of the application's state and exploit the memory hierarchy in the machine. However, as the energy cost of data movement continues to dominate, further reductions in checkpoint size are needed. Lossy compression, which can significantly reduce checkpoint sizes, offers a potential to reduce computational cost in checkpoint restart. This article investigates the use of numerical properties of partial differential equation (PDE) simulations, such as bounds on the truncation error, to evaluate the feasibility of using lossy compression in checkpointing PDE simulations. Restart from a checkpoint with lossy compression is considered for a fail-stop error in two time-dependent HPC application codes: PlasComCM and Nek5000. Results show that error in application variables due to a restart from a lossy compressed checkpoint can be masked by the numerical error in the discretization, leading to increased efficiency in checkpoint restart without influencing overall accuracy in the simulation. },
	Author = {Jon Calhoun and Franck Cappello and Luke N Olson and Marc Snir and William D Gropp},
	Date-Added = {2018-03-24 21:57:52 +0000},
	Date-Modified = {2018-03-24 21:57:52 +0000},
	Doi = {10.1177/1094342018762036},
	Eprint = {https://doi.org/10.1177/1094342018762036},
	Journal = {The International Journal of High Performance Computing Applications},
	Number = {0},
	Pages = {1094342018762036},
	Title = {Exploring the feasibility of lossy compression for {PDE} simulations},
	Url = {https://doi.org/10.1177/1094342018762036},
	Volume = {27},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1177/1094342018762036}}

@article{hierarchical1984,
	Acmid = {356930},
	Address = {New York, NY, USA},
	Author = {Samet, Hanan},
	Doi = {10.1145/356924.356930},
	Issn = {0360-0300},
	Issue_Date = {June 1984},
	Journal = {ACM Comput. Surv.},
	Month = jun,
	Number = {2},
	Numpages = {74},
	Pages = {187--260},
	Publisher = {ACM},
	Title = {The Quadtree and Related Hierarchical Data Structures},
	Url = {http://doi.acm.org/10.1145/356924.356930},
	Volume = {16},
	Year = {1984},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/356924.356930},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/356924.356930}}

@article{amr1989,
	Acmid = {1718335},
	Address = {San Diego, CA, USA},
	Author = {Berger, M. J. and Colella, P.},
	Doi = {10.1016/0021-9991(89)90035-1},
	Issn = {0021-9991},
	Issue_Date = {May, 1989},
	Journal = {J. Comput. Phys.},
	Month = may,
	Number = {1},
	Numpages = {21},
	Pages = {64--84},
	Publisher = {Academic Press Professional, Inc.},
	Title = {Local Adaptive Mesh Refinement for Shock Hydrodynamics},
	Url = {http://dx.doi.org/10.1016/0021-9991(89)90035-1},
	Volume = {82},
	Year = {1989},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/0021-9991(89)90035-1}}

@book{compression_techniques1991,
	Address = {Bellingham, WA, USA},
	Author = {Rabbani, Majid and Jones, Paul W.},
	Edition = {1st},
	Isbn = {0819406481},
	Publisher = {Society of Photo-Optical Instrumentation Engineers (SPIE)},
	Title = {Digital Image Compression Techniques},
	Year = {1991}}

@article{histogram_intersection1991,
	Abstract = {Computer vision is embracing a new research focus in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, realistic environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the location of a known object. Color can be successfully used for both tasks.},
	Author = {Swain, Michael J. and Ballard, Dana H.},
	Day = {01},
	Doi = {10.1007/BF00130487},
	Issn = {1573-1405},
	Journal = {International Journal of Computer Vision},
	Month = {Nov},
	Number = {1},
	Pages = {11--32},
	Title = {Color indexing},
	Url = {https://doi.org/10.1007/BF00130487},
	Volume = {7},
	Year = {1991},
	Bdsk-Url-1 = {https://doi.org/10.1007/BF00130487}}

@article{image_compression1992,
	Author = {R.A. DeVore and B. Jawerth and B.J. Lucier},
	Journal = {IEEE Trans. Inform. Theory},
	Month = march,
	Pages = {719--746},
	Title = {Image compression through wavelet transform coding},
	Volume = {38},
	Year = {1992}}

@inproceedings{vq1992,
	Acmid = {147152},
	Address = {New York, NY, USA},
	Author = {Ning, Paul and Hesselink, Lambertus},
	Booktitle = {Proceedings of the 1992 Workshop on Volume Visualization},
	Doi = {10.1145/147130.147152},
	Isbn = {0-89791-527-5},
	Location = {Boston, Massachusetts, USA},
	Numpages = {6},
	Pages = {69--74},
	Publisher = {ACM},
	Series = {VVS '92},
	Title = {Vector Quantization for Volume Rendering},
	Url = {http://doi.acm.org/10.1145/147130.147152},
	Year = {1992},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/147130.147152},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/147130.147152}
}

@article{spiht1996,
	Author = {A. Said and W. A. Pearlman},
	Doi = {10.1109/76.499834},
	Issn = {1051-8215},
	Journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	Keywords = {arithmetic codes;codecs;data compression;entropy codes;image coding;image reconstruction;transform coding;trees (mathematics);wavelet transforms;arithmetic code;decoding;decoding algorithm;embedded zerotree wavelet coding;entropy coding;file sizes;image codec;image coding;image compression;image reconstruction;image wavelet transform;ordered bit plane transmission;partial ordering;performance;self-similarity;set partitioning in hierarchical trees;set partitioning sorting algorithm;Codecs;Decoding;Image coding;Image reconstruction;Partitioning algorithms;Performance loss;Signal processing;Signal processing algorithms;Sorting;Wavelet transforms},
	Month = {Jun},
	Number = {3},
	Pages = {243-250},
	Title = {A new, fast, and efficient image codec based on set partitioning in hierarchical trees},
	Volume = {6},
	Year = {1996},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/76.499834}}

@inproceedings{emd1998,
	Author = {Y. Rubner and C. Tomasi and L. J. Guibas},
	Booktitle = {Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)},
	Doi = {10.1109/ICCV.1998.710701},
	Keywords = {image colour analysis;image texture;visual databases;color;distributions;easy-to-compute lower bounds;image databases;linear optimization;multi-dimensional scaling displays;partial matching;texture;transportation problem;Application software;Computer displays;Computer science;Frequency;Geoscience;Histograms;Image databases;Image retrieval;Navigation;Psychology},
	Month = {Jan},
	Pages = {59-66},
	Title = {A metric for distributions with applications to image databases},
	Year = {1998},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ICCV.1998.710701}}

@inproceedings{multires_octree1999,
	Acmid = {319432},
	Address = {Los Alamitos, CA, USA},
	Author = {LaMar, Eric and Hamann, Bernd and Joy, Kenneth I.},
	Booktitle = {Proceedings of the Conference on Visualization '99: Celebrating Ten Years},
	Isbn = {0-7803-5897-X},
	Keywords = {hardware texture, multiresolution rendering, volume visualization},
	Location = {San Francisco, California, USA},
	Numpages = {7},
	Pages = {355--361},
	Publisher = {IEEE Computer Society Press},
	Series = {VIS '99},
	Title = {Multiresolution Techniques for Interactive Texture-based Volume Visualization},
	Url = {http://dl.acm.org/citation.cfm?id=319351.319432},
	Year = {1999},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=319351.319432}}

@inproceedings{sbhp2000,
	Author = {C. Chrysafis and A. Said and A. Drukarev and A. Islam and W. A. Pearlman},
	Booktitle = {2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)},
	Doi = {10.1109/ICASSP.2000.859233},
	Issn = {1520-6149},
	Keywords = {code standards;computational complexity;data compression;entropy codes;image coding;transform coding;wavelet transforms;JPEG2000 image compression standard framework;SBHP;algorithm;compression performance;embedded coding;entropy coding;low complexity wavelet coder;low-complexity entropy coder;nonembedded coding;subband-block hierarchical partitioning;verification model;wavelet coefficients;Algorithm design and analysis;Code standards;Entropy coding;Image coding;Partitioning algorithms;Performance loss;Testing;Transform coding;Virtual manufacturing;Wavelet coefficients},
	Pages = {2035-2038 vol.4},
	Title = {{SBHP}-a low complexity wavelet coder},
	Volume = {6},
	Year = {2000},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ICASSP.2000.859233}}

@article{jpeg2001,
	Author = {A. Skodras and C. Christopoulos and T. Ebrahimi},
	Doi = {10.1109/79.952804},
	Issn = {1053-5888},
	Journal = {IEEE Signal Processing Magazine},
	Keywords = {ISO standards;code standards;data compression;entropy codes;image coding;quantisation (signal);reviews;standardisation;telecommunication standards;transform coding;wavelet transforms;ISO/IEC;JPEG 2000 still image compression standard;Part I standard;entropy coding;error resilience;file format;image tiling;international standard;multicomponent transformations;performance comparisons;quantization;region-of-interest coding;scalability;standardization committee;visual weighting;wavelet transforms;Entropy coding;IEC standards;ISO standards;Image coding;Quantization;Resilience;Scalability;Standardization;Transform coding;Wavelet transforms},
	Month = {Sep},
	Number = {5},
	Pages = {36-58},
	Title = {The JPEG 2000 still image compression standard},
	Volume = {18},
	Year = {2001},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/79.952804}}

@inproceedings{idx2001,
	Author = {V. Pascucci and R. J. Frank},
	Booktitle = {Supercomputing, ACM/IEEE 2001 Conference},
	Doi = {10.1145/582034.582036},
	Keywords = {Cache memory;Computer displays;Data visualization;Degradation;Grid computing;Indexing;Laboratories;Multiprocessing systems;Portable computers;Random access memory},
	Month = {Nov},
	Pages = {45-45},
	Title = {Global Static Indexing for Real-Time Exploration of Very Large Regular Grids},
	Year = {2001},
	Bdsk-Url-1 = {https://dx.doi.org/10.1145/582034.582036}}

@inproceedings{compression_domain2003,
	Author = {J. Schneider and R. Westermann},
	Booktitle = {IEEE Visualization, 2003. VIS 2003.},
	Doi = {10.1109/VISUAL.2003.1250385},
	Keywords = {computer graphic equipment;image texture;rendering (computer graphics);vector quantisation;CPU;GPU;commodity graphics hardware;compression domain volume rendering;data transfer;gigabyte data sets;graphics processing unit;hierarchical quantization;multiresolution covariance analysis;programmable hardware;real-time rendering;temporal coherence;texture mapping hardware;texture memory;time-varying volumetric data set;vector quantization;Central Processing Unit;Computer graphics;Data visualization;Decoding;Encoding;Hardware;Large-scale systems;Rendering (computer graphics);Shock waves;Vector quantization},
	Month = {Oct},
	Pages = {293-300},
	Title = {Compression domain volume rendering},
	Year = {2003},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/VISUAL.2003.1250385}}

@inproceedings{multires_toolkit2003,
	Author = {Clyne, John},
	Booktitle = {Proc. Visualization, Imaging, and Image Processing},
	Pages = {152-157},
	Title = {The multiresolution toolkit: Progressive access for regular gridded data},
	Year = {2003}}

@inproceedings{tf_decompression2004,
	Author = {P. Ljung and C. Lundstrom and A. Ynnerman and K. Museth},
	Booktitle = {2004 IEEE Symposium on Volume Visualization and Graphics},
	Doi = {10.1109/SVVG.2004.14},
	Keywords = {biomedical imaging;data compression;image coding;medical computing;rendering (computer graphics);transfer functions;wavelet transforms;compressed wavelet transformed blocks;image decompression;image quality;image rendering;medical imaging;medical transfer functions;multiresolution data representation;standard volumetric data sets;volume compression;volume rendering;Bandwidth;Biomedical imaging;Computed tomography;Data visualization;Image coding;Image resolution;Medical diagnostic imaging;Pipelines;Rendering (computer graphics);Transfer functions;Adaptive decompression;Image quality measures;Medical imaging;Multiresolution;Transfer function;Volume compression;Volume rendering;Wavelet transform},
	Month = {Oct},
	Pages = {25-32},
	Title = {Transfer function based adaptive decompression for volume rendering of large medical data sets},
	Year = {2004},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/SVVG.2004.14}}

@article{speck2004,
	Author = {W. A. Pearlman and A. Islam and N. Nagaraj and A. Said},
	Doi = {10.1109/TCSVT.2004.835150},
	Issn = {1051-8215},
	Journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	Keywords = {block codes;computational complexity;data compression;discrete cosine transforms;entropy codes;image coding;image colour analysis;optimisation;pattern clustering;transform coding;trees (mathematics);wavelet transforms;color image coding;discrete cosine transform;dyadic image transform;energy clustering;entropy coding;hierarchical trees;image wavelet transform coding algorithm;lossless coding;low-complexity image coding;rate distortion optimization;recursive set-partitioning embedded block coder;reversible coding;sorting mechanism;wavelet packets;Clustering algorithms;Color;Discrete cosine transforms;Discrete wavelet transforms;Frequency;Image coding;Partitioning algorithms;Transform coding;Wavelet coefficients;Wavelet packets;Color image coding;embedded coding;entropy coding;hierarchical coding;image coding;lossless coding;wavelet coding},
	Month = {Nov},
	Number = {11},
	Pages = {1219-1235},
	Title = {Efficient, low-complexity image coding with a set-partitioning embedded block coder},
	Volume = {14},
	Year = {2004},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TCSVT.2004.835150}}

@article{vapor2007,
	Author = {John Clyne and Pablo Mininni and Alan Norton and Mark Rast},
	Journal = {New Journal of Physics},
	Number = {8},
	Pages = {301},
	Title = {Interactive desktop analysis of high resolution simulations: {A}pplication to turbulent plume dynamics and current sheet formation},
	Url = {http://stacks.iop.org/1367-2630/9/i=8/a=301},
	Volume = {9},
	Year = {2007},
	Bdsk-Url-1 = {http://stacks.iop.org/1367-2630/9/i=8/a=301}}

@article{hw_dvr2007,
	Author = {N. Fout and K. L. Ma},
	Doi = {10.1109/TVCG.2007.70516},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {computer graphic equipment;data compression;real-time systems;rendering (computer graphics);transform coding;GPU;compression quality;decompression;dequantization;graphics memory;hardware-accelerated volume rendering;inverse transform;large volume data sets;real-time volume rendering;software volume rendering;transform coding;volumetric compression;Data visualization;Decoding;Encoding;Graphics;Hardware;Pipelines;Production;Rendering (computer graphics);Resource management;Transform coding;Compressed Volume Rendering;Hardware-accelerated Volume Rendering;Transform Coding;Volume Compression},
	Month = {Nov},
	Number = {6},
	Pages = {1600-1607},
	Title = {Transform Coding for Hardware-accelerated Volume Rendering},
	Volume = {13},
	Year = {2007},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2007.70516}}

@inproceedings{woodring2011,
	Author = {J. Woodring and S. Mniszewski and C. Brislawn and D. DeMarle and J. Ahrens},
	Booktitle = {2011 IEEE Symposium on Large Data Analysis and Visualization},
	Doi = {10.1109/LDAV.2011.6092314},
	Keywords = {data analysis;data compression;data visualisation;electronic data interchange;environmental science computing;expert systems;production engineering computing;wavelet transforms;JPEG 2000;data analysis;data compression community;data precision;data quality;data transfer;data visualization;domain expert;large-scale climate data;large-scale data reading;large-scale data size;large-scale data writing;parallel ocean program data;production scientific computing;quality metric;remotely compressed POP data;signal processing;standard-based method;wavelet compression;Bit rate;Data visualization;Image coding;Quantization;Transform coding;Wavelet transforms},
	Month = {Oct},
	Pages = {31-38},
	Title = {Revisiting wavelet compression for large-scale climate data using {JPEG} 2000 and ensuring data precision},
	Year = {2011},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/LDAV.2011.6092314}}

@article{covra2012,
	Author = {Gobbetti, Enrico and Iglesias Guiti{\'a}n, Jos{\'e} Antonio and Marton, Fabio},
	Doi = {10.1111/j.1467-8659.2012.03124.x},
	Issn = {1467-8659},
	Journal = {Computer Graphics Forum},
	Keywords = {Computer Graphics [I.3.3]: Picture/Image Generation---, Computer Graphics [I.3.7]: Three-dimensional graphics and realism---, Coding and Information Theory [E.4]: Data compaction and compression---, Compression (Coding) [I.4.2]: Approximate methods---},
	Number = {3pt4},
	Pages = {1315--1324},
	Publisher = {Blackwell Publishing Ltd},
	Title = {{COVRA}: A compression-domain output-sensitive volume rendering architecture based on a sparse representation of voxel blocks},
	Url = {http://dx.doi.org/10.1111/j.1467-8659.2012.03124.x},
	Volume = {31},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/j.1467-8659.2012.03124.x}}

@article{vdb2013,
	Acmid = {2487235},
	Address = {New York, NY, USA},
	Articleno = {27},
	Author = {Museth, Ken},
	Doi = {10.1145/2487228.2487235},
	Issn = {0730-0301},
	Issue_Date = {June 2013},
	Journal = {ACM Trans. Graph.},
	Keywords = {Volumes, fluid animation, implicit surfaces, level sets},
	Month = jul,
	Number = {3},
	Numpages = {22},
	Pages = {27:1--27:22},
	Publisher = {ACM},
	Title = {{VDB}: High-resolution Sparse Volumes with Dynamic Topology},
	Url = {http://doi.acm.org/10.1145/2487228.2487235},
	Volume = {32},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2487228.2487235},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2487228.2487235}}

@inproceedings{compression_sim2013,
	Address = {Denver, CO, USA},
	Author = {Daniel E. Laney and Steven Langer and Christopher Weber and Peter Lindstrom and Al Wegener},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.org/rec/bib/conf/sc/LaneyLWLW13},
	Booktitle = {International Conference for High Performance Computing, Networking, Storage and Analysis, SC'13},
	Date-Modified = {2018-03-24 21:55:31 +0000},
	Doi = {10.1145/2503210.2503283},
	Month = {Nov},
	Pages = {76:1--76:12},
	Timestamp = {Mon, 05 Jun 2017 12:39:52 +0200},
	Title = {Assessing the effects of data compression in simulations using physically motivated metrics},
	Url = {http://doi.acm.org/10.1145/2503210.2503283},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2503210.2503283},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2503210.2503283}}

@article{spgrid2014,
	Acmid = {2661269},
	Address = {New York, NY, USA},
	Articleno = {205},
	Author = {Setaluri, Rajsekhar and Aanjaneya, Mridul and Bauer, Sean and Sifakis, Eftychios},
	Doi = {10.1145/2661229.2661269},
	Issn = {0730-0301},
	Issue_Date = {November 2014},
	Journal = {ACM Trans. Graph.},
	Keywords = {adaptive discretizations, fluid simulation, sparse grids},
	Month = nov,
	Number = {6},
	Numpages = {12},
	Pages = {205:1--205:12},
	Publisher = {ACM},
	Title = {SPGrid: A Sparse Paged Grid Structure Applied to Adaptive Smoke Simulation},
	Url = {http://doi.acm.org/10.1145/2661229.2661269},
	Volume = {33},
	Year = {2014},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2661229.2661269},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2661229.2661269}}

@article{zfp2014,
	Author = {P. Lindstrom},
	Doi = {10.1109/TVCG.2014.2346458},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {computer graphics;data compression;data visualisation;embedded systems;floating point arithmetic;graphics processing units;random-access storage;storage management;bit rate selection;data access;data visualization;embedded coding;fixed-point arithmetic operations;fixed-precision values;fixed-rate compressed floating-point arrays;fixed-rate texture compression methods;floating-point data;graphics hardware;hardware implementation;lossy compression;memory management;near-lossless compression scheme;numerical simulation;orthogonal block transform;per-block bit stream;quantitative data analysis;read and write random access;scientific applications;software write-back cache;variable-length bit stream;Bandwidth allocation;Computational modeling;Data visualization;Encoding;Floating-point arithmetic;Image coding;Data compression;embedded coding;floating-point arrays;orthogonal block transform},
	Month = {Dec},
	Number = {12},
	Pages = {2674-2683},
	Title = {Fixed-Rate Compressed Floating-Point Arrays},
	Volume = {20},
	Year = {2014},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2014.2346458}}

@article{tensor_dvr2015,
	Acmid = {2902848},
	Address = {Elmsford, NY, USA},
	Author = {Ballester-Ripoll, Rafael and Suter, Susanne K. and Pajarola, Renato},
	Doi = {10.1016/j.cag.2014.10.002},
	Issn = {0097-8493},
	Issue_Date = {April 2015},
	Journal = {Comput. Graph.},
	Keywords = {Canonical decomposition, Higher-order decompositions, Tensor approximation, Tensor rank truncation, Tucker decomposition, Volume visualization},
	Month = apr,
	Number = {C},
	Numpages = {14},
	Pages = {34--47},
	Publisher = {Pergamon Press, Inc.},
	Title = {Analysis of Tensor Approximation for Compression-domain Volume Visualization},
	Url = {http://dx.doi.org/10.1016/j.cag.2014.10.002},
	Volume = {47},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.cag.2014.10.002}}

@inproceedings{tamresh,
	Acmid = {2600556},
	Address = {Chichester, UK},
	Author = {Suter, S. K. and Makhynia, M. and Pajarola, R.},
	Booktitle = {Proceedings of the 15th Eurographics Conference on Visualization},
	Doi = {10.1111/cgf.12102},
	Location = {Leipzig, Germany},
	Numpages = {10},
	Pages = {151--160},
	Publisher = {The Eurographs Association and John Wiley \& Sons, Ltd.},
	Series = {EuroVis '13},
	Title = {TAMRESH - Tensor Approximation Multiresolution Hierarchy for Interactive Volume Visualization},
	Url = {http://dx.doi.org/10.1111/cgf.12102},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/cgf.12102}}

@article{fpzip,
	Acmid = {1187859},
	Address = {Piscataway, NJ, USA},
	Author = {Lindstrom, Peter and Isenburg, Martin},
	Doi = {10.1109/TVCG.2006.143},
	Issn = {1077-2626},
	Issue_Date = {September 2006},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {High throughput, High throughput, lossless compression, file compaction for I/O efficiency, fast entropy coding, range coder, predictive coding, large scale simulation and visualization., fast entropy coding, file compaction for I/O efficiency, large scale simulation and visualization., lossless compression, predictive coding, range coder},
	Month = sep,
	Number = {5},
	Numpages = {6},
	Pages = {1245--1250},
	Publisher = {IEEE Educational Activities Department},
	Title = {Fast and Efficient Compression of Floating-Point Data},
	Url = {http://dx.doi.org/10.1109/TVCG.2006.143},
	Volume = {12},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/TVCG.2006.143}}

@inproceedings{sz,
	Author = {D. Tao and S. Di and Z. Chen and F. Cappello},
	Booktitle = {2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
	Doi = {10.1109/IPDPS.2017.115},
	Keywords = {data compression;parallel processing;HPC applications;adaptive error-controlled quantization encoder;error-controlled lossy compression algorithm;multidimensional prediction;multilayer prediction formulas;normalized root mean squared error;scientific data sets;Adaptation models;Compression algorithms;Data models;Encoding;Measurement;Predictive models;Quantization (signal)},
	Month = {May},
	Pages = {1129-1139},
	Title = {Significantly Improving Lossy Compression for Scientific Data Sets Based on Multidimensional Prediction and Error-Controlled Quantization},
	Year = {2017},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/IPDPS.2017.115}}

@inproceedings{hvg,
	Author = {J. Schneider and R. Westermann},
	Booktitle = {IEEE Visualization, 2003. VIS 2003.},
	Doi = {10.1109/VISUAL.2003.1250385},
	Keywords = {computer graphic equipment;image texture;rendering (computer graphics);vector quantisation;CPU;GPU;commodity graphics hardware;compression domain volume rendering;data transfer;gigabyte data sets;graphics processing unit;hierarchical quantization;multiresolution covariance analysis;programmable hardware;real-time rendering;temporal coherence;texture mapping hardware;texture memory;time-varying volumetric data set;vector quantization;Central Processing Unit;Computer graphics;Data visualization;Decoding;Encoding;Hardware;Large-scale systems;Rendering (computer graphics);Shock waves;Vector quantization},
	Month = {Oct},
	Pages = {293-300},
	Title = {Compression domain volume rendering},
	Year = {2003},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/VISUAL.2003.1250385}}

@inproceedings{isabela,
	Abstract = {Modern large-scale scientific simulations running on HPC systems generate data in the order of terabytes during a single run. To lessen the I/O load during a simulation run, scientists are forced to capture data infrequently, thereby making data collection an inherently lossy process. Yet, lossless compression techniques are hardly suitable for scientific data due to its inherently random nature; for the applications used here, they offer less than 10{\%} compression rate. They also impose significant overhead during decompression, making them unsuitable for data analysis and visualization that require repeated data access.},
	Address = {Berlin, Heidelberg},
	Author = {Lakshminarasimhan, Sriram and Shah, Neil and Ethier, Stephane and Klasky, Scott and Latham, Rob and Ross, Rob and Samatova, Nagiza F.},
	Booktitle = {Euro-Par 2011 Parallel Processing},
	Editor = {Jeannot, Emmanuel and Namyst, Raymond and Roman, Jean},
	Isbn = {978-3-642-23400-2},
	Pages = {366--379},
	Publisher = {Springer Berlin Heidelberg},
	Title = {Compressing the Incompressible with {ISABELA}: In-situ Reduction of Spatio-temporal Data},
	Year = {2011}}

@inproceedings{sqe,
	Acmid = {2402519},
	Address = {Berlin, Heidelberg},
	Author = {Iverson, Jeremy and Kamath, Chandrika and Karypis, George},
	Booktitle = {Proceedings of the 18th International Conference on Parallel Processing},
	Doi = {10.1007/978-3-642-32820-6_83},
	Isbn = {978-3-642-32819-0},
	Location = {Rhodes Island, Greece},
	Numpages = {14},
	Pages = {843--856},
	Publisher = {Springer-Verlag},
	Series = {Euro-Par '12},
	Title = {Fast and Effective Lossy Compression Algorithms for Scientific Datasets},
	Url = {http://dx.doi.org/10.1007/978-3-642-32820-6_83},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-642-32820-6_83}}

@inproceedings{codar,
	Abstract = {A growing disparity between supercomputer computation speeds and I/O rates makes it increasingly infeasible for applications to save all results for offline analysis. Instead, applications must analyze and reduce data online so as to output only those results needed to answer target scientific question(s). This change in focus complicates application and experiment design and introduces algorithmic, implementation, and programming model challenges that are unfamiliar to many scientists and that have major implications for the design of various elements of supercomputer systems. We review these challenges and describe methods and tools that we are developing to enable experimental exploration of algorithmic, software, and system design alternatives.},
	Address = {Cham},
	Author = {Foster, Ian and Ainsworth, Mark and Allen, Bryce and Bessac, Julie and Cappello, Franck and Choi, Jong Youl and Constantinescu, Emil and Davis, Philip E. and Di, Sheng and Di, Wendy and Guo, Hanqi and Klasky, Scott and Van Dam, Kerstin Kleese and Kurc, Tahsin and Liu, Qing and Malik, Abid and Mehta, Kshitij and Mueller, Klaus and Munson, Todd and Ostouchov, George and Parashar, Manish and Peterka, Tom and Pouchard, Line and Tao, Dingwen and Tugluk, Ozan and Wild, Stefan and Wolf, Matthew and Wozniak, Justin M. and Xu, Wei and Yoo, Shinjae},
	Booktitle = {Euro-Par 2017: Parallel Processing},
	Editor = {Rivera, Francisco F. and Pena, Tom{\'a}s F. and Cabaleiro, Jos{\'e} C.},
	Isbn = {978-3-319-64203-1},
	Pages = {3--19},
	Publisher = {Springer International Publishing},
	Title = {Computing Just What You Need: Online Data Analysis and Reduction at Extreme Scales},
	Year = {2017}}

@article{li2018,
author = {Li, S. and Marsaglia, N. and Garth, C. and Woodring, J. and Clyne, J. and Childs, H.},
title = {Data Reduction Techniques for Simulation, Visualization and Data Analysis},
journal = {Computer Graphics Forum},
volume = {0},
number = {0},
pages = {},
keywords = {data reduction techniques, simulation, data analysis, survey, General and reference → Document types → Surveys and overviews, Information systems → Data management systems → Data structures → Data layout → Data compression},
doi = {10.1111/cgf.13336},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.13336},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13336},
abstract = {Abstract Data reduction is increasingly being applied to scientific data for numerical simulations, scientific visualizations and data analyses. It is most often used to lower I/O and storage costs, and sometimes to lower in‐memory data size as well. With this paper, we consider five categories of data reduction techniques based on their information loss: (1) truly lossless, (2) near lossless, (3) lossy, (4) mesh reduction and (5) derived representations. We then survey available techniques in each of these categories, summarize their properties from a practical point of view and discuss relative merits within a category. We believe, in total, this work will enable simulation scientists and visualization/data analysis scientists to decide which data reduction techniques will be most helpful for their needs.}
}


@article{laplacian-pyramid,
	Author = {P. Burt and E. Adelson},
	Doi = {10.1109/TCOM.1983.1095851},
	Issn = {0090-6778},
	Journal = {IEEE Transactions on Communications},
	Keywords = {Image coding;Data compression;Data structures;Entropy;Frequency;Image coding;Image sampling;Laplace equations;Low pass filters;Pixel;Shape},
	Month = {Apr},
	Number = {4},
	Pages = {532-540},
	Title = {The {L}aplacian Pyramid as a Compact Image Code},
	Volume = {31},
	Year = {1983},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TCOM.1983.1095851}}

@article{weiss,
	Author = {K. Weiss and P. Lindstrom},
	Doi = {10.1109/TVCG.2015.2467412},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {data visualisation;interpolation;inverse transforms;mesh generation;octrees;piecewise linear techniques;quadtrees;rendering (computer graphics);splines (mathematics);tensors;adaptive mesh elements;adaptive multilinear tensor product wavelets;adaptive nonconforming quadtree mesh;adaptive regular refinement;crack-free quadtree mesh;direct volume rendering;foundational visualization techniques;globally continuous functions;inverse wavelet transform;isosurfacing;linear B-splines;multilinear cells;nonzero wavelet coefficients;octree mesh;piecewise multilinear interpolation;texture mapping;Interpolation;Octrees;Splines (mathematics);Tensile stress;Wavelet domain;Wavelet transforms;Multilinear interpolation;adaptive wavelets;continuous reconstruction;multiresolution models;octrees},
	Month = {Jan},
	Number = {1},
	Pages = {985-994},
	Title = {Adaptive Multilinear Tensor Product Wavelets},
	Volume = {22},
	Year = {2016},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2015.2467412}}

@article{ezw,
	Author = {J. M. Shapiro},
	Doi = {10.1109/78.258085},
	Issn = {1053-587X},
	Journal = {IEEE Transactions on Signal Processing},
	Keywords = {binary sequences;codecs;data compression;image coding;trees (mathematics);video equipment;wavelet transforms;EZW;adaptive arithmetic coding;binary decisions sequence;bit stream;discrete wavelet transform;embedded zerotree wavelet algorithm;entropy-coded successive-approximation quantization;fully embedded code;hierarchical subband decomposition;image compression algorithm;self-similarity;target distortion metric;target rate;universal lossless data compression;wavelet coefficients;Bit rate;Compression algorithms;Decoding;Discrete wavelet transforms;Image coding;Quantization;Rate distortion theory;Streaming media;Testing;Wavelet coefficients},
	Month = {Dec},
	Number = {12},
	Pages = {3445-3462},
	Title = {Embedded image coding using zerotrees of wavelet coefficients},
	Volume = {41},
	Year = {1993},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/78.258085}}

@article{treib,
	Author = {M. Treib and K. B{\"u}rger and F. Reichl and C. Meneveau and A. Szalay and R. Westermann},
	Doi = {10.1109/TVCG.2012.274},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {computational fluid dynamics;data visualisation;encoding;entropy;graphics processing units;ray tracing;turbulence;GPU memory;GPU system;bandwidth capacities;brick-based volume ray-casting;compressed flow field representation;desktop computers;entropy encoding;feature-based turbulence visualization;interactive selection;large-scale turbulent motions;memory capacities;run-length;simultaneous visualization;small-scale turbulent motions;spatio-temporal resolution;terascale on desktop PCs;turbulence properties;turbulence small-scale structure;unsteady turbulence simulations;velocity gradient tensor;visually guided exploration;wavelet-based compression scheme;Data visualization;Encoding;Graphics processing unit;Memory management;Rendering (computer graphics);Tensile stress;Vectors;Visualization system and toolkit design;data compression;data streaming;vector fields;volume rendering},
	Month = {Dec},
	Number = {12},
	Pages = {2169-2177},
	Title = {Turbulence Visualization at the Terascale on Desktop {PC}s},
	Volume = {18},
	Year = {2012},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2012.274}}

@inproceedings{level-of-detail-volume-rendering,
	Acmid = {353889},
	Address = {New York, NY, USA},
	Author = {Weiler, Manfred and Westermann, R\"{u}diger and Hansen, Chuck and Zimmermann, Kurt and Ertl, Thomas},
	Booktitle = {Proceedings of the 2000 IEEE Symposium on Volume Visualization},
	Doi = {10.1145/353888.353889},
	Isbn = {1-58113-308-1},
	Location = {Salt Lake City, Utah, USA},
	Numpages = {7},
	Pages = {7--13},
	Publisher = {ACM},
	Series = {VVS '00},
	Title = {Level-of-detail Volume Rendering via {3D} Textures},
	Url = {http://doi.acm.org/10.1145/353888.353889},
	Year = {2000},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/353888.353889},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/353888.353889}}

@inproceedings{sph-octree,
	Author = {F. Reichl and M. Treib and R. Westermann},
	Booktitle = {2013 IEEE International Conference on Big Data},
	Doi = {10.1109/BigData.2013.6691717},
	Keywords = {data compression;data visualisation;octrees;ray tracing;rendering (computer graphics);wavelet transforms;GPU;Interactive visualization;big SPH simulation;compressed octree grids;grid resolution;high-quality visualization;multiresolution multiblock grid;particle distribution;rendering;spatial dimension;spatially continuous 3D field;view-aligned grid;volume ray-casting;wavelet-based compression;Discrete wavelet transforms;Graphics processing units;Instruction sets;Octrees;Rendering (computer graphics);Smoothing methods;Three-dimensional displays;SPH;data compression;volume rendering},
	Month = {Oct},
	Pages = {71-78},
	Title = {Visualization of big {SPH} simulations via compressed octree grids},
	Year = {2013},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/BigData.2013.6691717}}

@article{Gobbetti2008,
	Abstract = {We present an adaptive out-of-core technique for rendering massive scalar volumes employing single-pass GPU ray casting. The method is based on the decomposition of a volumetric dataset into small cubical bricks, which are then organized into an octree structure maintained out-of-core. The octree contains the original data at the leaves, and a filtered representation of children at inner nodes. At runtime an adaptive loader, executing on the CPU, updates a view and transfer function-dependent working set of bricks maintained on GPU memory by asynchronously fetching data from the out-of-core octree representation. At each frame, a compact indexing structure, which spatially organizes the current working set into an octree hierarchy, is encoded in a small texture. This data structure is then exploited by an efficient stackless ray casting algorithm, which computes the volume rendering integral by visiting non-empty bricks in front-to-back order and adapting sampling density to brick resolution. Block visibility information is fed back to the loader to avoid refinement and data loading of occluded zones. The resulting method is able to interactively explore multi-gigavoxel datasets on a desktop PC. },
	Author = {Gobbetti, Enrico and Marton, Fabio and Iglesias Guiti{\'a}n, Jos{\'e} Antonio},
	Day = {01},
	Doi = {10.1007/s00371-008-0261-9},
	Issn = {1432-2315},
	Journal = {The Visual Computer},
	Month = {Jul},
	Number = {7},
	Pages = {797--806},
	Title = {A single-pass {GPU} ray casting framework for interactive out-of-core rendering of massive volumetric datasets},
	Url = {https://doi.org/10.1007/s00371-008-0261-9},
	Volume = {24},
	Year = {2008},
	Bdsk-Url-1 = {https://doi.org/10.1007/s00371-008-0261-9}}

@article{visualization-driven,
	Author = {M. Hadwiger and J. Beyer and W. K. Jeong and H. Pfister},
	Doi = {10.1109/TVCG.2012.240},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {data acquisition;data visualisation;electron microscopes;microscopy;virtual storage;2D microscope image tiles;3D blocks;3D multiresolution representation;anisotropic petascale volume;best-of-breed system;cache misses;continuous stream;data acquisition;decouples construction;high resolution electron microscopy image;interactive volume exploration;microscopes;multiresolution hierarchy;multiresolution virtual memory architecture;neuroscience;octree;petascale microscopy data streams;petascale volumes;ray-casting;real microscopy data;system design;visible volume data;visualization-driven virtual memory;volume ray casting;volume visualization system;Data visualization;Graphics processing unit;Image resolution;Microscopy;Neuroscience;Octrees;Rendering (computer graphics);Petascale volume exploration;high-resolution microscopy;high-throughput imaging;neuroscience;0},
	Month = {Dec},
	Number = {12},
	Pages = {2285-2294},
	Title = {Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach},
	Volume = {18},
	Year = {2012},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2012.240}}

@inproceedings{multires-framework,
	Acmid = {197963},
	Address = {New York, NY, USA},
	Author = {Westermann, R\"{u}diger},
	Booktitle = {Proceedings of the 1994 Symposium on Volume Visualization},
	Doi = {10.1145/197938.197963},
	Isbn = {0-89791-741-3},
	Location = {Tysons Corner, Virginia, USA},
	Numpages = {8},
	Pages = {51--58},
	Publisher = {ACM},
	Series = {VVS '94},
	Title = {A Multiresolution Framework for Volume Rendering},
	Url = {http://doi.acm.org/10.1145/197938.197963},
	Year = {1994},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/197938.197963},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/197938.197963}}

@article{volume-wavelet,
	Author = {S. Muraki},
	Doi = {10.1109/38.219451},
	Issn = {0272-1716},
	Journal = {IEEE Computer Graphics and Applications},
	Keywords = {image processing;wavelet transforms;1D functions;3D orthogonal wavelet transforms;MR;magnetic resonance;real volume data;Computed tomography;Computer graphics;Discrete wavelet transforms;Laboratories;Laplace equations;Multidimensional systems;Object recognition;Shape;Signal resolution;Wavelet transforms},
	Month = {July},
	Number = {4},
	Pages = {50-56},
	Title = {Volume data and wavelet transforms},
	Volume = {13},
	Year = {1993},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/38.219451}}

@article{compression-domain-volume-rendering,
	Abstract = {This paper describes a method for volume data compression and rendering which bases on wavelet splats. The underlying concept is especially designed for distributed and networked applications, where we assume a remote server to maintain large scale volume data sets, being inspected, browsed through and rendered interactively by a local client. Therefore, we encode the server's volume data using a newly designed wavelet based volume compression method. A local client can render the volumes immediately from the compression domain by using wavelet footprints, a method proposed earlier. In addition, our setup features full progression, where the rendered image is refined progressively as data comes in. Furthermore, framerate constraints are considered by controlling the quality of the image both locally and globally depending on the current network bandwidth or computational capabilities of the client. As a very important aspect of our setup, the client does not need to provide storage for the volume data and can be implemented in terms of a network application. The underlying framework enables to exploit all advantageous properties of the wavelet transform and forms a basis for both sophisticated lossy compression and rendering. Although coming along with simple illumination and constant exponential decay, the rendering method is especially suited for fast interactive inspection of large data sets and can be supported easily by graphics hardware.},
	Author = {L. Lippert and M.H. Gross and C. Kurmann},
	Doi = {10.1111/1467-8659.00146},
	Eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-8659.00146},
	Journal = {Computer Graphics Forum},
	Keywords = {volume rendering, multiresolution, progressive compression, splatting, wavelets, networks, distributed applications},
	Number = {3},
	Pages = {C95-C107},
	Title = {Compression Domain Volume Rendering for Distributed Environments},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.00146},
	Volume = {16},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.00146},
	Bdsk-Url-2 = {https://dx.doi.org/10.1111/1467-8659.00146}}

@inproceedings{interactive-rendering-large-volume,
	Acmid = {602106},
	Address = {Washington, DC, USA},
	Author = {Guthe, Stefan and Wand, Michael and Gonser, Julius and Strasser, Wolfgang},
	Booktitle = {Proceedings of the Conference on Visualization '02},
	Isbn = {0-7803-7498-3},
	Keywords = {compression algorithms, level of detail algorithms, scientific visualization, volume rendering, wavelets},
	Location = {Boston, Massachusetts},
	Numpages = {8},
	Pages = {53--60},
	Publisher = {IEEE Computer Society},
	Series = {VIS '02},
	Title = {Interactive Rendering of Large Volume Data Sets},
	Url = {http://dl.acm.org/citation.cfm?id=602099.602106},
	Year = {2002},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=602099.602106}}

@article{multiscale-tensor,
	Author = {S. K. Suter and J. A. Iglesias Guitian and F. Marton and M. Agus and A. Elsener and C. P. E. Zollikofer and M. Gopi and E. Gobbetti and R. Pajarola},
	Doi = {10.1109/TVCG.2011.214},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {computer graphic equipment;coprocessors;data visualisation;interactive systems;natural sciences computing;rendering (computer graphics);CUDA;GPU accelerated out-of-core multiresolution rendering framework;GPU accelerated tensor reconstruction;computational simulations;constrained memory footprint;data transfer bandwidth;gigabyte sized microtomographic volumes;hierarchical brick tensor decomposition approach;high resolution 3D imaging devices;interactive multiscale tensor reconstruction;interactive visual analysis;multiresolution volume visualization;out-of-core memory footprint;tensor approximation;Approximation methods;Graphics processing unit;Instruction sets;Quantization;Rendering (computer graphics);Tensile stress;GPU/CUDA;interactive volume visualization;multiresolution rendering.;multiscale;tensor reconstruction;Algorithms;Animals;Computer Graphics;Computer Simulation;Databases, Factual;Hominidae;Imaging, Three-Dimensional;Lizards;Models, Anatomic;Molar;X-Ray Microtomography},
	Month = {Dec},
	Number = {12},
	Pages = {2135-2143},
	Title = {Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization},
	Volume = {17},
	Year = {2011},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2011.214}}

@inproceedings{evaluating-compression-climate,
	Acmid = {2600217},
	Address = {New York, NY, USA},
	Author = {Baker, Allison H. and Xu, Haiying and Dennis, John M. and Levy, Michael N. and Nychka, Doug and Mickelson, Sheri A. and Edwards, Jim and Vertenstein, Mariana and Wegener, Al},
	Booktitle = {Proceedings of the 23rd International Symposium on High-performance Parallel and Distributed Computing},
	Doi = {10.1145/2600212.2600217},
	Isbn = {978-1-4503-2749-7},
	Keywords = {data compression, high performance computing},
	Location = {Vancouver, BC, Canada},
	Numpages = {12},
	Pages = {203--214},
	Publisher = {ACM},
	Series = {HPDC '14},
	Title = {A Methodology for Evaluating the Impact of Data Compression on Climate Simulation Data},
	Url = {http://doi.acm.org/10.1145/2600212.2600217},
	Year = {2014},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2600212.2600217},
	Bdsk-Url-2 = {https://dx.doi.org/10.1145/2600212.2600217}}

@article{verifiable-isosurface,
	Author = {T. Etiene and C. Scheidegger and L. G. Nonato and R. M. Kirby and C. Silva},
	Doi = {10.1109/TVCG.2009.194},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {image coding;image representation;convergence rate;isosurface extraction codes;isosurface features;visual representations;Computational modeling;Convergence;Data mining;Data visualization;Heart;Isosurfaces;Mathematical model;Numerical simulation;Pipelines;Scientific computing;Isosurface Extraction;Marching Cubes;V&V;Verification},
	Month = {Nov},
	Number = {6},
	Pages = {1227-1234},
	Title = {Verifiable Visualization for Isosurface Extraction},
	Volume = {15},
	Year = {2009},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2009.194}}

@article{survey-multires,
	Author = {Jesus Pulido and Daniel Livescu and Jonathan Woodring and James Ahrens and Bernd Hamann},
	Doi = {https://doi.org/10.1016/j.compfluid.2015.11.001},
	Issn = {0045-7930},
	Journal = {Computers \& Fluids},
	Keywords = {Turbulence, Wavelet, Curvelet, Surfacelet, B-spline wavelet},
	Pages = {39 - 58},
	Title = {Survey and analysis of multiresolution methods for turbulence data},
	Url = {http://www.sciencedirect.com/science/article/pii/S004579301500362X},
	Volume = {125},
	Year = {2016},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S004579301500362X},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.compfluid.2015.11.001}}

@article{verifying-volume-rendering,
	Author = {T. Etiene and D. J{\"o}nsson and T. Ropinski and C. Scheidegger and J. L. D. Comba and L. G. Nonato and R. M. Kirby and A. Ynnerman and C. T. Silva},
	Doi = {10.1109/TVCG.2013.90},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {data visualisation;error analysis;rendering (computer graphics);DVR algorithms;Riemann summation;continuous model;convergence curves;discretization error analysis;expected approximation errors;grid size;pixel size;volume rendering correctness verification approach;volume rendering integral analysis;Error analysis;Rendering (computer graphics);Testing;Volume measurements;Discretization errors;testing;verifiable visualization;verification;volume rendering},
	Month = {Jan},
	Number = {1},
	Pages = {140-154},
	Title = {Verifying Volume Rendering Using Discretization Error Analysis},
	Volume = {20},
	Year = {2014},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2013.90}}

@inproceedings{evaluating-efficacy-wavelet,
	Author = {S. Li and K. Gruchalla and K. Potter and J. Clyne and H. Childs},
	Booktitle = {2015 IEEE 5th Symposium on Large Data Analysis and Visualization (LDAV)},
	Doi = {10.1109/LDAV.2015.7348075},
	Keywords = {data analysis;data compression;data visualisation;image coding;parallel machines;wavelet transforms;data compression;data visualization;image processing;scientific data analysis;simulation code;supercomputer;turbulent-flow visualization tool;wavelet configuration;Data compression;Data visualization;Image coding;Kernel;Wavelet analysis;Wavelet transforms},
	Month = {Oct},
	Pages = {81-89},
	Title = {Evaluating the efficacy of wavelet configurations on turbulent-flow data},
	Year = {2015},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/LDAV.2015.7348075}}

@inproceedings{image-based-in-tisu-vis,
	Author = {J. Ahrens and S. Jourdain and P. OLeary and J. Patchett and D. H. Rogers and M. Petersen},
	Booktitle = {SC14: International Conference for High Performance Computing, Networking, Storage and Analysis},
	Doi = {10.1109/SC.2014.40},
	Issn = {2167-4329},
	Keywords = {data analysis;data visualisation;image processing;public domain software;software tools;extreme scale data analysis;extreme scale in situ visualization;extreme scale scientific simulations;interactive image-based approach;open source tools;Analytical models;Atmospheric modeling;Cameras;Computational modeling;Data models;Data visualization;Databases},
	Month = {Nov},
	Pages = {424-434},
	Title = {An Image-Based Approach to Extreme Scale in Situ Visualization and Analysis},
	Year = {2014},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/SC.2014.40}}

@inproceedings{in-situ-sampling-particle,
	Acmid = {2422022},
	Address = {Chichester, UK},
	Author = {Woodring, J. and Ahrens, J. and Figg, J. and Wendelberger, J. and Habib, S. and Heitmann, K.},
	Booktitle = {Proceedings of the 13th Eurographics / IEEE - VGTC Conference on Visualization},
	Doi = {10.1111/j.1467-8659.2011.01964.x},
	Location = {Bergen, Norway},
	Numpages = {10},
	Pages = {1151--1160},
	Publisher = {The Eurographs Association and John Wiley \& Sons, Ltd.},
	Series = {EuroVis '11},
	Title = {In-situ Sampling of a Large-scale Particle Simulation for Interactive Visualization and Analysis},
	Url = {http://dx.doi.org/10.1111/j.1467-8659.2011.01964.x},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1111/j.1467-8659.2011.01964.x}}

@article{rapid-compression-volume,
	Abstract = {Volume data sets resulting from, e.g., computerized tomography (CT) or magnetic resonance (MR) imaging modalities require enormous storage capacity even at moderate resolution levels. Such large files may require compression for processing in CPU memory which, however, comes at the cost of decoding times and some loss in reconstruction quality with respect to the original data. For many typical volume visualization applications (rendering of volume slices, subvolumes of interest, or isosurfaces) only a part of the volume data needs to be decoded. Thus, efficient compression techniques are needed that provide random access and rapid decompression of arbitrary parts the volume data. We propose a technique which is block based and operates in the wavelet transformed domain. We report performance results which compare favorably with previously published methods yielding large reconstruction quality gains from about 6 to 12 dB in PSNR for a5123 ‐volume extracted from the Visible Human data set. In terms of compression our algorithm compressed the data 6 times as much as the previous state‐of‐the‐art block based coder for a given PSNR quality.},
	Author = {Ky Giang Nguyen and Dietmar Saupe},
	Doi = {10.1111/1467-8659.00497},
	Eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-8659.00497},
	Journal = {Computer Graphics Forum},
	Number = {3},
	Pages = {49-57},
	Title = {Rapid High Quality Compression of Volume Data for Visualization},
	Url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.00497},
	Volume = {20},
	Bdsk-Url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.00497},
	Bdsk-Url-2 = {https://dx.doi.org/10.1111/1467-8659.00497}}

@article{wavelet-compression-interactive-vis,
author = {Ihm, Insung and Park, Sanghun},
title = {Wavelet‐Based 3D Compression Scheme for Interactive Visualization of Very Large Volume Data},
journal = {Computer Graphics Forum},
volume = {18},
number = {1},
pages = {3-15},
keywords = {very large volume data, wavelets, 3D compression, fast random access, Visible Human data, interactive visualization},
doi = {10.1111/1467-8659.00298},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-8659.00298},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-8659.00298},
abstract = {Interactive visualization of very large volume data has been recognized as a task requiring great effort in a variety of science and engineering fields. In particular, such data usually places considerable demands on run‐time memory space. In this paper, we present an effective 3D compression scheme for interactive visualization of very large volume data, that exploits the power of wavelet theory. In designing our method, we have compromised between two important factors: high compression ratio and fast run‐time random access ability. Our experimental results on the Visual Human data sets show that our method achieves fairly good compression ratios. In addition, it minimizes the overhead caused during run‐time reconstruction of voxel values. This 3D compression scheme will be useful in developing many interactive visualization systems for huge volume data, especially when they are based on personal computers or workstations with limited memory.}
}

@inproceedings{mloc,
	Author = {Z. Gong and T. Rogers and J. Jenkins and H. Kolla and S. Ethier and J. Chen and R. Ross and S. Klasky and N. F. Samatova},
	Booktitle = {2012 41st International Conference on Parallel Processing},
	Doi = {10.1109/ICPP.2012.39},
	Issn = {0190-3918},
	Keywords = {data compression;data reduction;distributed databases;natural sciences computing;network operating systems;optimisation;query processing;sampling methods;spatiotemporal phenomena;storage management;I/O systems;MLOC;combinatorial access pattern space;compressed scientific data exploration;compressed scientific spatiotemporal data;compression-driven data reduction;data size issue;database management technologies;exploratory data-intensive analytics;extreme-scale datasets;heterogeneous access patterns;multifile data partitioning;multilevel architecture;multilevel layout optimization framework;multiple fine-grained data layout optimization kernels;multiresolution data extraction;multiresolution data sampling;parallel file systems;precision-driven data analytics;query driven multivariate spatiotemporal constraints;query-driven data exploration;runtime environments;scientific simulations;storage capability;Data compression;Data models;Kernel;Layout;Optimization;Organizations;Throughput},
	Month = {Sept},
	Pages = {239-248},
	Title = {{MLOC}: Multi-level Layout Optimization Framework for Compressed Scientific Data Exploration with Heterogeneous Access Patterns},
	Year = {2012},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/ICPP.2012.39}}

@inproceedings{Fogal-2013-RayGuided,
	Author = {Thomas Fogal AND Alexander Schiewe AND Jens Kr\"uger},
	Booktitle = {2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV)},
	Title = {{An Analysis of Scalable GPU-Based Ray-Guided Volume Rendering}},
	Url = {http://www.sci.utah.edu/~tfogal/academic/ray-guided/Fogal-Analysis.pdf},
	Year = {2013},
	Bdsk-Url-1 = {http://www.sci.utah.edu/~tfogal/academic/ray-guided/Fogal-Analysis.pdf}}

@inproceedings{fogal-kdtree,
	Acmid = {1921489},
	Address = {Aire-la-Ville, Switzerland, Switzerland},
	Author = {Fogal, Thomas and Childs, Hank and Shankar, Siddharth and Kr\"uger, Jens and Bergeron, R. Daniel and Hatcher, Philip},
	Booktitle = {Proceedings of the Conference on High Performance Graphics},
	Location = {Saarbrucken, Germany},
	Numpages = {10},
	Pages = {57--66},
	Publisher = {Eurographics Association},
	Series = {HPG '10},
	Title = {Large Data Visualization on Distributed Memory multi-{GPU} Clusters},
	Url = {http://dl.acm.org/citation.cfm?id=1921479.1921489},
	Year = {2010},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1921479.1921489}}

@article{multires-volume-rendering,
	Author = {S. Guthe and W. Strasser},
	Doi = {https://doi.org/10.1016/j.cag.2003.10.018},
	Issn = {0097-8493},
	Journal = {Computers \& Graphics},
	Keywords = {Viewing algorithms, Data compaction and compression},
	Number = {1},
	Pages = {51 - 58},
	Title = {Advanced techniques for high-quality multi-resolution volume rendering},
	Url = {http://www.sciencedirect.com/science/article/pii/S0097849303002292},
	Volume = {28},
	Year = {2004},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0097849303002292},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cag.2003.10.018}}

@inproceedings{out-of-core-algorithms,
	Author = {Cl{\'a}udio Silva and Yi-jen Chiang and Wagner Corr{\^e}a and Jihad El-sana and Peter Lindstrom},
	Booktitle = {In Visualization'02 Course Notes},
	Title = {Out-of-core algorithms for scientific visualization and computer graphics},
	Year = {2002}}

@inproceedings{interactive-exploration-ct-scans,
	Author = {S. Prohaska and A. Hutanu and R. Kahler and H. C. Hege},
	Booktitle = {IEEE Visualization 2004},
	Doi = {10.1109/VISUAL.2004.51},
	Keywords = {computerised tomography;data visualisation;grid computing;image resolution;medical image processing;GridFTP protocol;data processing pipeline;hierarchical volume tenderer;human vertebral body;image resolution;imaging technology;interactive visualization;remote microCT scans;Biomedical imaging;Bones;Data processing;Data visualization;Detectors;Humans;Image resolution;Information retrieval;Osteoporosis;Pipelines},
	Month = {Oct},
	Pages = {345-352},
	Title = {Interactive exploration of large remote micro-{CT} scans},
	Year = {2004},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/VISUAL.2004.51}}

@article{topology-verification-isosurface,
	Author = {T. Etiene and L. G. Nonato and C. Scheidegger and J. Tienry and T. J. Peters and V. Pascucci and R. M. Kirby and C. T. Silva},
	Doi = {10.1109/TVCG.2011.109},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {computational geometry;data visualisation;topology;algorithmic implementations;digital topology;isosurface coding mistakes;isosurface extraction;stratified Morse theory;topological invariant verification;topology verification;verifiable visualization;Face;Interpolation;Isosurfaces;Level set;Manifolds;Software;Topology;Verifiable visualization;isosurface;topology.},
	Month = {June},
	Number = {6},
	Pages = {952-965},
	Title = {Topology Verification for Isosurface Extraction},
	Volume = {18},
	Year = {2012},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2011.109}}

@article{statistical-volume-quality,
	Author = {C. Wang and K. L. Ma},
	Doi = {10.1109/TVCG.2007.70628},
	Issn = {1077-2626},
	Journal = {IEEE Transactions on Visualization and Computer Graphics},
	Keywords = {data analysis;quality management;statistical analysis;wavelet transforms;data analysis;feature functions;large-scale data sets;predefined distance functions;reduced-reference approach;statistical approach;volume data quality assessment;wavelet domain;Statistical computing;Volume visualization;Algorithms;Computer Graphics;Data Interpretation, Statistical;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity},
	Month = {May},
	Number = {3},
	Pages = {590-602},
	Title = {A Statistical Approach to Volume Data Quality Assessment},
	Volume = {14},
	Year = {2008},
	Bdsk-Url-1 = {https://dx.doi.org/10.1109/TVCG.2007.70628}}

@article{state-of-the-art-compressed-volume,
	Acmid = {3071836},
	Address = {Chichester, UK},
	Author = {Balsa Rodr\'{\i}guez, M. and Gobbetti, E. and Iglesias Guiti\'{a}n, J.A. and Makhinya, M. and Marton, F. and Pajarola, R. and Suter, S.K.},
	Doi = {10.1111/cgf.12280},
	Issn = {0167-7055},
	Issue_Date = {September 2014},
	Journal = {Comput. Graph. Forum},
	Keywords = {Computer Graphics [I.3.3]: Picture/Image Generation Computer Graphics [I.3.7]: Three-dimensional graphics and realism Coding and Information Theory [E.4]: Data compaction and compression Compression Coding [I.4.2]: Approximate methods, GPU, compression models, compression-domain direct volume rendering, decoding strategies, decompression architectures, large volume data visualization, level-of-detail representations, preprocessing and encoding, sampling grid layouts, time-varying volume data visualization},
	Month = sep,
	Number = {6},
	Numpages = {24},
	Pages = {77--100},
	Publisher = {The Eurographs Association and John Wiley \& Sons, Ltd.},
	Title = {State-of-the-Art in Compressed {GPU}-Based Direct Volume Rendering},
	Url = {https://doi.org/10.1111/cgf.12280},
	Volume = {33},
	Year = {2014},
	Bdsk-Url-1 = {https://doi.org/10.1111/cgf.12280}}

@article{tucker-thresholding,
	Acmid = {3011576},
	Address = {Secaucus, NJ, USA},
	Author = {Ballester-Ripoll, Rafael and Pajarola, Renato},
	Doi = {10.1007/s00371-015-1130-y},
	Issn = {0178-2789},
	Issue_Date = {November 2016},
	Journal = {The Visual Computer},
	Keywords = {Data compression, Higher-order decompositions, Multidimensional data encoding, Tensor approximation, Tensor rank reduction},
	Month = nov,
	Number = {11},
	Numpages = {14},
	Pages = {1433--1446},
	Publisher = {Springer-Verlag New York, Inc.},
	Title = {Lossy Volume Compression Using {T}ucker Truncation and Thresholding},
	Url = {http://dx.doi.org/10.1007/s00371-015-1130-y},
	Volume = {32},
	Year = {2016},
}

@ARTICLE{quantifying-coding-performance, 
  author={Y. Cho and W. A. Pearlman}, 
  journal={IEEE Transactions on Signal Processing}, 
  title={Quantifying the Coding Performance of Zerotrees of Wavelet Coefficients: Degree-k Zerotree}, 
  year={2007},
  volume={55}, 
  number={6}, 
  pages={2425-2431}, 
  keywords={image coding;statistics;tree codes;wavelet transforms;SPIHT;coding performance;degree-k zerotree;image wavelet transforms;wavelet coefficients;zerotree coder;Image analysis;Image coding;Image processing;Performance analysis;Quantization;Sorting;Statistical analysis;Wavelet analysis;Wavelet coefficients;Wavelet transforms;EZW;SPIHT;wavelet image compression;zero tree;zerotree coder}, 
  doi={10.1109/TSP.2007.893218}, 
  ISSN={1053-587X}, 
  month={June},
}

@inproceedings{zfp-arc,
  author = {P. Lindstrom},
  title = {Reducing Data Movement using Adaptive-Rate Computing},
  addendum = {Poster presented at ARC},
  note = {\url{https://computation.llnl.gov/sites/default/files/public//llnl-post-728998.pdf} (accessed on June 13, 2018)},
  url = {https://computation.llnl.gov/sites/default/files/public//llnl-post-728998.pdf},
}

@book{jpeg2000,
 author = {Taubman, David S. and Marcellin, Michael W.},
 title = {JPEG 2000: Image Compression Fundamentals, Standards and Practice},
 year = {2001},
 isbn = {079237519X},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
}

@inproceedings{gigavoxels,
 author = {Crassin, Cyril and Neyret, Fabrice and Lefebvre, Sylvain and Eisemann, Elmar},
 title = {GigaVoxels: Ray-guided Streaming for Efficient and Detailed Voxel Rendering},
 booktitle = {Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games},
 series = {I3D '09},
 year = {2009},
 isbn = {978-1-60558-429-4},
 location = {Boston, Massachusetts},
 pages = {15--22},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1507149.1507152},
 doi = {10.1145/1507149.1507152},
 acmid = {1507152},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{large‐scale-volume,
	author = {Johanna Beyer and Markus Hadwiger and Hanspeter Pfister},
	title = {State-of-the-Art in {GPU}-Based Large-Scale Volume Visualization},
	journal = {Computer Graphics Forum},
	volume = {34},
	number = {8},
	pages = {13-37},
	keywords = {STAR, volume rendering, ray‐guided, large data, GPU, I.3.6 Computer Graphics: Methodology and Techniques—I.3.3 Computer Graphics: Picture/Image Generation—Display algorithms},
	doi = {10.1111/cgf.12605},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12605},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12605},
	abstract = {Abstract This survey gives an overview of the current state of the art in GPU techniques for interactive large‐scale volume visualization. Modern techniques in this field have brought about a sea change in how interactive visualization and analysis of giga‐, tera‐ and petabytes of volume data can be enabled on GPUs. In addition to combining the parallel processing power of GPUs with out‐of‐core methods and data streaming, a major enabler for interactivity is making both the computational and the visualization effort proportional to the amount and resolution of data that is actually visible on screen, i.e. ‘output‐sensitive’ algorithms and system designs. This leads to recent output‐sensitive approaches that are ‘ray‐guided’, ‘visualization‐driven’ or ‘display‐aware’. In this survey, we focus on these characteristics and propose a new categorization of GPU‐based large‐scale volume visualization techniques based on the notions of actual output‐resolution visibility and the current working set of volume bricks—the current subset of data that is minimally required to produce an output image of the desired display resolution. Furthermore, we discuss the differences and similarities of different rendering and data traversal strategies in volume rendering by putting them into a common context—the notion of address translation. For our purposes here, we view parallel (distributed) visualization using clusters as an orthogonal set of techniques that we do not discuss in detail but that can be used in conjunction with what we present in this survey.}
}

@patent{apax,
  author = {A. Wegener},
  title = {Adaptive compression and decompression of bandlimited signals},
  numer = {7009533},
  year = {2006},
  month = {3},
}

@article{z-checker,
  author    = {Dingwen Tao and
               Sheng Di and
               Hanqi Guo and
               Zizhong Chen and
               Franck Cappello},
  title     = {Z-checker: {A} Framework for Assessing Lossy Compression of Scientific
               Data},
  journal   = {CoRR},
  volume    = {abs/1707.09320},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.09320},
  archivePrefix = {arXiv},
  eprint    = {1707.09320},
  timestamp = {Sat, 05 Aug 2017 14:56:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/TaoDGCC17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{cdf-wavelets,
  author = {A. Cohen and Ingrid Daubechies and J.‐C. Feauveau},
  title = {Biorthogonal bases of compactly supported wavelets},
  journal = {Communications on Pure and Applied Mathematics},
  volume = {45},
  number = {5},
  pages = {485-560},
  doi = {10.1002/cpa.3160450502},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.3160450502},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpa.3160450502},
  abstract = {Abstract Orthonormal bases of compactly supported wavelet bases correspond to subband coding schemes with exact reconstruction in which the analysis and synthesis filters coincide. We show here that under fairly general conditions, exact reconstruction schemes with synthesis filters different from the analysis filters give rise to two dual Riesz bases of compactly supported wavelets. We give necessary and sufficient conditions for biorthogonality of the corresponding scaling functions, and we present a sufficient conditions for the decay of their Fourier transforms. We study the regularity of these biorthogonal bases. We provide several families of examples, all symmetric (corresponding to “linear phase” filters). In particular we can construct symmetric biorthogonal wavelet bases with arbitraily high preassigned regularity; we also show how to construct symmetric biorthogonal wavelet bases “close” to a (nonsymmetric) orthonormal basis.}
}

@article{smirnov1948,
	author = "Smirnov, N.",
	doi = "10.1214/aoms/1177730256",
	fjournal = "The Annals of Mathematical Statistics",
	journal = "Ann. Math. Statist.",
	month = "06",
	number = "2",
	pages = "279--281",
	publisher = "The Institute of Mathematical Statistics",
	title = "Table for Estimating the Goodness of Fit of Empirical Distributions",
	url = "https://doi.org/10.1214/aoms/1177730256",
	volume = "19",
	year = "1948"
}

@article{kullback1951,
	author = "Kullback, S. and Leibler, R. A.",
	doi = "10.1214/aoms/1177729694",
	fjournal = "The Annals of Mathematical Statistics",
	journal = "Ann. Math. Statist.",
	month = "03",
	number = "1",
	pages = "79--86",
	publisher = "The Institute of Mathematical Statistics",
	title = "On Information and Sufficiency",
	url = "https://doi.org/10.1214/aoms/1177729694",
	volume = "22",
	year = "1951"
}

@INPROCEEDINGS{levina2001, 
	author={E. Levina and P. Bickel}, 
	booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001}, 
	title={The Earth Mover's distance is the Mallows distance: some insights from statistics}, 
	year={2001}, 
	volume={2}, 
	number={}, 
	pages={251-256 vol.2}, 
	keywords={image classification;image processing;probability;Earth Mover's distance;Mallows distance;color similarities;probability distributions;texture classification;Earth;Euclidean distance;Fluid flow measurement;Humans;Image retrieval;Image segmentation;Multidimensional systems;Physics;Probability distribution;Statistics}, 
	doi={10.1109/ICCV.2001.937632}, 
	ISSN={}, 
	month={},
}

@article{Hellinger1909,
	author = {Hellinger, E.},
	journal = {Journal f{\"u}r die reine und angewandte Mathematik},
	pages = {210-271},
	title = {Neue Begr{\"u}ndung der Theorie quadratischer Formen von unendlichvielen Ver{\"a}nderlichen.},
	url = {http://eudml.org/doc/149313},
	volume = {136},
	year = {1909},
}

@article{Bhattacharyya1943,
	author = {Bhattacharyya, A.},
	citeulike-article-id = {7675294},
	journal = {Bulletin of the Calcutta Mathematical Society},
	keywords = {distance},
	pages = {99--109},
	pdf = {pdf/1943/Bhattacharyya1943.pdf},
	posted-at = {2010-08-17 23:24:49},
	priority = {0},
	title = {{On a measure of divergence between two statistical populations defined by their probability distributions}},
	volume = {35},
	year = {1943}
}

@INPROCEEDINGS{turbulence,
  title={Turbulence simulations on {O}(10000) processors},
  author={Donzis, Diego A and Yeung, PK and Pekurovsky, Dmitry},
  booktitle={Proceedings of TeraGrid 2008 Conference},
  year={2008}
}


@misc{kingsnake,
        author = {Colbert, Matthew},
        title = {Lampropeltis getula, Common Kingsnake},
        note = {DigiMorph},
        year={2003},
        month={Oct},
}
@INPROCEEDINGS{transfer-function-based, 
	author={P. Ljung and C. Lundstrom and A. Ynnerman and K. Museth}, 
	booktitle={2004 IEEE Symposium on Volume Visualization and Graphics}, 
	title={Transfer function based adaptive decompression for volume rendering of large medical data sets}, 
	year={2004}, 
	volume={}, 
	number={}, 
	pages={25-32}, 
	keywords={biomedical imaging;data compression;image coding;medical computing;rendering (computer graphics);transfer functions;wavelet transforms;compressed wavelet transformed blocks;image decompression;image quality;image rendering;medical imaging;medical transfer functions;multiresolution data representation;standard volumetric data sets;volume compression;volume rendering;Bandwidth;Biomedical imaging;Computed tomography;Data visualization;Image coding;Image resolution;Medical diagnostic imaging;Pipelines;Rendering (computer graphics);Transfer functions;Adaptive decompression;Image quality measures;Medical imaging;Multiresolution;Transfer function;Volume compression;Volume rendering;Wavelet transform}, 
	doi={10.1109/SVVG.2004.14}, 
	ISSN={}, 
	month={Oct},
}

@article{cook_cabot_miller_2004,
  title={The mixing transition in {R}ayleigh-{T}aylor instability},
	volume={511}, 
	DOI={10.1017/S0022112004009681},
	journal={Journal of Fluid Mechanics},
	publisher={Cambridge University Press}, 
	author={Cook, Andrew W. and Cabot, William and Miller, Paul L.},
	year={2004}, 
	pages={333–362}
}

@INPROCEEDINGS{boiler, 
	author={P. Smith and J. Thornock and Y. Wu and S. Smith and B. Isaac}, 
	booktitle={15th International Conference on Numerical Combustion (NC '15)}, 
	title={Oxy-Coal Power Boiler Simulation and Validation Through Extreme Computing}, 
	year={2015}
}

@article{magnetic,
	Author = {Fan Guo and Hui Li and William Daughton and Yi-Hsin Liu},
	Title = {Formation of Hard Power-laws in the Energetic Particle Spectra Resulting from Relativistic Magnetic Reconnection},
	Year = {2014},
	Eprint = {arXiv:1405.4040},
	Howpublished = {Guo et al. 2014, Physical Review Letters, 113, 155005},
	Doi = {10.1103/PhysRevLett.113.155005},
}

@article{foam,
	title = "A multiscale comparison of stochastic open-cell aluminum foam produced via conventional and additive-manufacturing routes",
	journal = "Materials Science and Engineering: A",
	volume = "707",
	pages = "181 - 192",
	year = "2017",
	issn = "0921-5093",
	doi = "https://doi.org/10.1016/j.msea.2017.08.102",
	url = "http://www.sciencedirect.com/science/article/pii/S0921509317311346",
	author = "Kristoffer E. Matheson and Kory K. Cross and Matthew M. Nowell and Ashley D. Spear",
	keywords = "Casting, Rapid solidification, Mechanical characterization, EBSD, Tomography, Cellular materials"
}