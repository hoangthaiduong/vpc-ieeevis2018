\subsection{Computation of derivatives}
\label{sec:derivatives}

Computation of derivative quantities such as gradient and Laplacian is of fundamental importance in
data analysis. In this section, we study streams that aim to minimize errors of derivative fields.
For the experiments in this section, we quantize the data to $32$ instead of $16$ bits, to ensure
enough precision for the purpose of taking derivatives using finite differences of floating-point
values. Note that in this paper, for the purpose of derivative computation, we always perform finite
differences on the finest (original) resolution. This is possible since the wavelet transform allows
for reconstruction of the function at the original resolution. The reason for this decision is to
avoid the problem of computing distances between quantities across grids of different dimensions
(e.g., computing the root-mean-square error between a (down-sampled) $n\times n$ grid and a
$2n\times 2n$ grid), because we are unaware of solutions to this problem. In the following Sections,
we perform experiments with two of the most common types of derivative, namely gradient and
Laplacian.

\subsubsection{Gradient}

Since simulation data can rarely be captured by closed-form formulas, we use finite difference to
compute gradients. We experiment with three popular finite difference schemes using stencil size
widths of two, three, and five points in each dimension: $\frac{\partial f}{\partial x}\approx
f(x+1)-f(x)
\approx \frac{1}{2}f(x+1)-\frac{1}{2}f(x-1) \approx
\frac{1}{12}f(x-2)-\frac{2}{3}f(x-1)+\frac{2}{3}f(x+1)-\frac{1}{12}f(x+2)$. In 2D, the gradient at
each grid point $(x,y)$ is the vector $(\frac{\partial f}{\partial x},\frac{\partial f}{\partial
y})$. We use the greedy algorithm in Section (\ref{sec:data_dep_streams} to compute a
\emph{gradient-optimized} stream that minimizes the difference between the gradient field of $f_b$
(the reconstructed function using $b$ bits per sample) and that of the original function ($f$). At
each grid point $p$, we compute an error $e(p)$, defined to be the squared Euclidean length of the
difference between two gradient vectors at $p$, that is $e(p)=\norm{\nabla f_b(p)-\nabla f(p)}^2$.
The overall error metric over the whole field, $E_g$, is defined as $E_g(\nabla f_b,\nabla
f)=\sqrt{\frac{1}{n}\sum_{i=1}^{n}{e(p_i)}}$.

We first want to quantify the effects (if any) that the stencil width has on the performance of
\emph{gradient-optimized} streams. For this experiment, we treat the gradient computed using the
five-point stencil on the finest resolution grid, at full precision, as the ``groundtruth'' gradient
field. Three \emph{gradient-optimized} streams (2-point, 3-point, and 5-point) are compared against
this groundtruth gradient field, using the error criteria $E_g$ defined above. The results are
plotted in Figure \ref{fig:gradient-stencil-comparison}. The plots show that the error curves for
all three stencils match one another closely, with the two-point stencil having negligibly higher
errors in some cases. This means in practice, a three-point stencil would likely strike a good
balance between the accuracy and speed. Since a slight increase in speed is not our main concern for
the experiments in this paper, we have chosen to use the five-point stencil always in the rest of
the section, noting that any conclusions drawn also apply to the other stencils.

\begin{figure}[h]
	\centering
	\subcaptionbox{boiler}
	{\includegraphics[width=0.48\linewidth]{img/gradient/compare-stencils/gradient-optimized-boiler.pdf}}
	\subcaptionbox{diffusivity}
	{\includegraphics[width=0.48\linewidth]{img/gradient/compare-stencils/gradient-optimized-diffusivity.pdf}}
	\subcaptionbox{euler}
	{\includegraphics[width=0.48\linewidth]{img/gradient/compare-stencils/gradient-optimized-euler.pdf}}
	\subcaptionbox{pressure}
	{\includegraphics[width=0.48\linewidth]{img/gradient/compare-stencils/gradient-optimized-pressure.pdf}}
	\subcaptionbox{marschner-lobb}
	{\includegraphics[width=0.48\linewidth]{img/gradient/compare-stencils/gradient-optimized-marschner-lobb.pdf}}
	\subcaptionbox{velocityz}
	{\includegraphics[width=0.48\linewidth]{img/gradient/compare-stencils/gradient-optimized-velocityz.pdf}}
	\caption{Gradient error for \emph{gradient-optimized} streams using different stencil widths,
	againts the ``groundtruth'' gradient, computed using 5-point finite difference on the original
	field. The plots are truncated towards the end, so as to better highlight differences between the
	curves. It can be seen that in most cases, there are no meaningful differences among the different
	stencil widths.}
	\label{fig:gradient-stencil-comparison}
\end{figure}

In the next experiment, we plot the gradient error curves produced by \emph{gradient-optimized},
together with ones produced by the \emph{by level}, \emph{by bit plane}, and \emph{by wavelet norm}
streams, for the same six data sets. These curves are plotted in Figure
\ref{fig:gradient-error-comparison}. \emph{gradient-optimized} typically performs far better than
the static streams, due to the fact that, with the knowledge of the data, this stream is able to
prioritize regions that would benefit the most from additional bits. Among the static streams,
\emph{by level} performs the worst, while \emph{by wavelet norm} performs slightly worse than the
other two streams. 

\begin{figure}[h]
	\centering
	\subcaptionbox{boiler}
	{\includegraphics[width=0.48\linewidth]{img/gradient/5points/gradient-optimized-boiler.pdf}}
	\subcaptionbox{diffusivity}
	{\includegraphics[width=0.48\linewidth]{img/gradient/5points/gradient-optimized-diffusivity.pdf}}
	\subcaptionbox{euler}
	{\includegraphics[width=0.48\linewidth]{img/gradient/5points/gradient-optimized-euler.pdf}}
	\subcaptionbox{pressure}
	{\includegraphics[width=0.48\linewidth]{img/gradient/5points/gradient-optimized-pressure.pdf}}
	\subcaptionbox{marschner-lobb}
	{\includegraphics[width=0.48\linewidth]{img/gradient/5points/gradient-optimized-marschner-lobb.pdf}}
	\subcaptionbox{velocityz}
	{\includegraphics[width=0.48\linewidth]{img/gradient/5points/gradient-optimized-velocityz.pdf}}
	\caption{Gradient error comparison among different streams, using the five-point stencil. The
	plots are truncated in the same way as in Figure \ref{fig:gradient-stencil-comparison}. In all
	cases, \emph{by wavelet norm} performs slightly worse than \emph{by bit plane} and \emph{gradient
	signature} do, but the differences are largely negligible. \emph{by level} performs the worst.}
	\label{fig:gradient-error-comparison}
\end{figure}

The differences in gradient errors among the streams in all cases are negligible. To give an
example, in Figure \ref{fig:gradient-rendering} we visualize the three reconstructed gradient fields
(using \emph{by bit plane}, \emph{by wavelet norm}, and \emph{gradient signature}, as well as the
groundtruth gradient field for the \emph{velocityz} data set, at 0.35 bps, where the streams diverge
the most. This figure shows that the differences among reconstructed gradient fields are barely
visible. For this reason, in practice, any static stream would likely suffice for the purpose of
computing gradient. However, \emph{by bit plane} is significantly cheaper to compute compared to
\emph{gradient signature}, because the latter requires obtaining \emph{gradient-optimized} first.
\emph{by wavelet norm} is also a reasonable alternative, especially if the bits are stored on disk
in the same order, for example, to optimize for root-mean-square errors (see Section
\ref{sec:motivation}. Finally, \emph{by wavelet norm} is also preferrable if, beside an accurate
gradient field, the task also requires an accurate function itself.

\begin{figure}[h]
	\centering
	\subcaptionbox{by wavelet norm}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_0_diff.png}}
	\subcaptionbox{by bit plane}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_1_diff.png}}
	\subcaptionbox{gradient signature}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_2_diff.png}}
	\subcaptionbox{gradient-optimized}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_3_diff.png}}
	\subcaptionbox{by wavelet norm}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_0.png}}
	\subcaptionbox{by bit plane}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_1.png}}
	\subcaptionbox{gradient signature}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_2.png}}
	\subcaptionbox{gradient-optimized}
	{\includegraphics[width=0.24\linewidth]{img/gradient/gradient_3.png}}
	\caption{Renderings of reconstructed gradient fields (bottom row), and differences, using the XOR
	operator (top row) from the groundtruth gradient field. \emph{velocityz}, 0.35 bps. The
	differences among the streams are barely noticable.}
  \label{fig:gradient-rendering}
\end{figure}

\begin{figure}[h]
	\centering
	\subcaptionbox{boiler's gradient, 2.39 bps}
	{\includegraphics[width=0.24\linewidth]{img/gradient/boiler-gradient.png}}
	\subcaptionbox{boiler's groundtruth gradient}
	{\includegraphics[width=0.24\linewidth]{img/gradient/boiler-groundtruth-gradient.png}}
	\subcaptionbox{euler's gradient, 0.25 bps}
	{\includegraphics[width=0.24\linewidth]{img/gradient/euler-gradient.png}}
	\subcaptionbox{euler's groundtruth gradient}
	{\includegraphics[width=0.24\linewidth]{img/gradient/euler-groundtruth-gradient.png}}
	\subcaptionbox{marschner-lobb's gradient, 1.55 bps}
	{\includegraphics[width=0.24\linewidth]{img/gradient/marschner-lobb-gradient.png}}
	\subcaptionbox{marschner-lobb's groundtruth gradient}
	{\includegraphics[width=0.24\linewidth]{img/gradient/marschner-lobb-groundtruth-gradient.png}}
	\subcaptionbox{diffusivity's gradient, 0.75 bps}
	{\includegraphics[width=0.24\linewidth]{img/gradient/diffusivity-gradient.png}}
	\subcaptionbox{diffusivity's groundtruth gradient}
	{\includegraphics[width=0.24\linewidth]{img/gradient/diffusivity-groundtruth-gradient.png}}
	\caption{Renderings of reconstructed gradient fields at low bit rates, compared to renderings of groundtruth gradient fields. The bit rates are chosen to be as low as possible, while largely capturing the visual fidelity of the results.}
  \label{fig:gradient-rendering}
\end{figure}

\begin{figure}[h]
	\centering
	\subcaptionbox{by wavelet norm}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func0-by-wavelet-norm-diff.png}}
	\subcaptionbox{by bit plane}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func1-by-bit-plane-diff.png}}
	\subcaptionbox{gradient signature}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func2-laplacian-signature-diff.png}}
	\subcaptionbox{gradient-optimized}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func3-laplacian-optimized-diff.png}}
	\subcaptionbox{by wavelet norm}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func0-by-wavelet-norm.png}}
	\subcaptionbox{by bit plane}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func1-by-bit-plane.png}}
	\subcaptionbox{gradient signature}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func2-laplacian-signature.png}}
	\subcaptionbox{gradient-optimized}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/curr_func3-laplacian-optimized.png}}
	\caption{Renderings of reconstructions of function (bottom row), and differences (XOR) from the groundtruth (top row). \emph{velocityz}, 1.28 bps. Although \emph{gradient signature} and \emph{by wavelet norm} produce same-quality gradient fields, \emph{by wavelet norm} produces a higher-quality function.}
  \label{fig:gradient-rendering}
\end{figure}

\subsubsection{Laplacian}

The Laplace operator is a second-order differential operator, defined as the divergence of the
gradient field. It can be computed by summing second partial derivatives in all dimensions, for
example, in 2D: $\Delta f=(\frac{{\partial}^2}{\partial{x^2}}+\frac{{\partial}^2}{\partial{y^2}})f$.
To approximate the Laplacian for data on a grid, we use the three-point finite difference to
approximate the second derivative in each dimension: $\frac{{\partial}^2}{\partial{x^2}}f(x,y)
\approx f(x-1,y)-2f(x,y)+f(x+1,y)$. The Laplacian error is defined as the root-mean-square error
between the Laplacian of the reconstructed scalar field and the Laplacian of the original scalar
field, that is, $E_g(\Delta f_b,\Delta f)=RMSE(\Delta f_b,\Delta f)$. For each data set, Algorithm
[REF] is used to compute a \emph{laplacian-optimized} bit stream that minimizes $E_g$ at any bit
rate. From this stream, we obtain its signature and construct the \emph{laplacian signature} stream,
which, unlike \emph{laplacian-optimized}, is considered static and hence can be implemented in
practice. In Figure \ref{fig:laplacian-error-comparison} we compare these two stream against all the
previously defined streams, including \emph{gradient-optimized} using $E_g$ as the metric.

\begin{figure}[h]
	\centering
	\subcaptionbox{boiler}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/laplacian-optimized-boiler.pdf}}
	\subcaptionbox{diffusivity}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/laplacian-optimized-diffusivity.pdf}}
	\subcaptionbox{euler, 5-point stencil}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/laplacian-optimized-euler.pdf}}
	\subcaptionbox{pressure, 5-point stencil}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/laplacian-optimized-pressure.pdf}}
	\subcaptionbox{marschner-lobb, 5-point stencil}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/laplacian-optimized-marschner-lobb.pdf}}
	\subcaptionbox{velocityz, 5-point stencil}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/laplacian-optimized-velocityz.pdf}}
	\caption{Laplacian error comparison among streams, using the three-point stencil. The plots are
	truncated so as to better highlight differences without discarding important information. In all cases, \emph{laplacian}}
	\label{fig:laplacian-error-comparison}
\end{figure}

\begin{figure}[h]
	\centering
	\subcaptionbox{boiler's laplacian, 4.0 bps}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/boiler-laplacian.png}}
	\subcaptionbox{boiler's groundtruth laplacian}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/boiler-groundtruth-laplacian.png}}
	\subcaptionbox{euler's laplacian, 0.64 bps}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/euler-laplacian.png}}
	\subcaptionbox{euler's groundtruth laplacian}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/euler-groundtruth-laplacian.png}}
	\subcaptionbox{marschner-lobb's laplacian, 3.9 bps}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/marschner-lobb-laplacian.png}}
	\subcaptionbox{marschner-lobb's groundtruth laplacian}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/marschner-lobb-groundtruth-laplacian.png}}
	\subcaptionbox{diffusivity's laplacian, 2.92 bps}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/diffusivity-laplacian.png}}
	\subcaptionbox{diffusivity's groundtruth laplacian}
	{\includegraphics[width=0.24\linewidth]{img/laplacian/diffusivity-groundtruth-laplacian.png}}
	\caption{Renderings of reconstructed Laplacian fields at low bit rates, compared to renderings of groundtruth gradient fields. The bit rates are chosen to be as low as possible, while largely capturing the visual fidelity of the results. Compared to the gradient case (Figure \ref{fig:gradient-rendering}), to achieve the same level of visual fidelity for the Laplacian fields requires bit rates that are two to three times higher.}
  \label{fig:gradient-rendering}
\end{figure}

It can be observed that unlike the case for gradient, there exists significant differences between
the \emph{rmse-optimized} and \emph{laplacian-optimized} streams with regards. To understand these
differences we plot the precision of every wavelet coefficients at a low bit rate in Figure
\ref{fig:laplacian-precision-comparison} (a and b). When cross refererencing this Figure with Figure
\ref{fig:gradient-comparison}b we see that the \emph{laplacian-optimized} stream priotizes
finer-resolution bits where the sharp shockwave is, unlike the \emph{rmse-optimized} stream which
prefers lower-ordered, coarse-resolution bits. This effect makes sense intuitively, as the
derivative operator makes functions less smooth, hence amplifing hard edges. This happens in the
gradient case too, but to a much lesser degree.

\begin{figure}[h]
	\centering
	\subcaptionbox{\emph{by wavelet norm}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/laplacian_0.png}}
	\subcaptionbox{\emph{by bit plane}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/laplacian_1.png}}
	\subcaptionbox{\emph{laplacian signature}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/laplacian_2.png}}
	\subcaptionbox{\emph{laplacian-optimized}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/laplacian_3.png}}
	\subcaptionbox{\emph{gradient signature}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/laplacian_4.png}}
	\subcaptionbox{\emph{groundtruth}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/groundtruth_laplacian_0.png}}
	\caption{Laplacian rendering, velocityz, 1.28bps. \emph{laplacian signature} incurs lowest level of visual artifacts among the static streams.}
	\label{fig:laplacian-precision-comparison}
\end{figure}

\begin{figure}[h]
	\subcaptionbox{\emph{by wavelet norm}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/by-wavelet-norm.png}}
	\subcaptionbox{\emph{by bit plane}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/by-bit-plane.png}}
	\subcaptionbox{\emph{laplacian signature}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/laplacian-signature.png}}
	\subcaptionbox{\emph{laplacian-optimized}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/laplacian-optimized.png}}
	\subcaptionbox{\emph{gradient signature}}
	{\includegraphics[width=0.32\linewidth]{img/laplacian/gradient-signature.png}}
	\caption{Precision map per subband (brigther is more precise) \emph{velocityz}, 1.28 bps. \emph{by wavelet norm} allocates more bits for the coarse-level subbands, while \emph{laplacian-optimized} and \emph{laplacian signature} do the opposite.}
	\label{fig:laplacian-precision-comparison}
\end{figure}

\emph{rmse-optimized}, \emph{laplacian-optimized}, and also \emph{gradient-optimized} for the euler
data set are visualized in Figure \ref{fig:signature-comparison}. 

TODO: add comparison of stream signatures
% \begin{figure}[h]
% 	\centering
% 	\subcaptionbox{\emph{rmse-optimized}}
% 	{\includegraphics[width=0.32\linewidth]{img/gradient-laplacian/SIG-GREEDY-(rmse).png}}
% 	\subcaptionbox{\emph{laplacian-optimized}}
% 	{\includegraphics[width=0.32\linewidth]{img/gradient-laplacian/SIG-GREEDY-(laplacian).png}}
% 	\subcaptionbox{\emph{gradient-optimized}}
% 	{\includegraphics[width=0.32\linewidth]{img/gradient-laplacian/SIG-GREEDY-(gradient).png}}
% 	\caption{Stream signatures visualized through a linear-blue color map (brighter is higher
% 	priority). From left to right: higher-ordered to lower-ordered bit planes. From top to bottom:
% 	coarser to finer subbands. Note that the streams from which the signatures are extracted do not
% 	contain leading zero bits, which explains the very dark cells }
% 	\label{fig:signature-comparison}
% \end{figure}

\begin{figure}[h]
	\centering
	\subcaptionbox{\emph{boiler}}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/SIG-(GREEDY)-(laplacian)-boiler.png}}
	\subcaptionbox{\emph{diffusivity}}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/SIG-(GREEDY)-(laplacian)-diffusivity.png}}
	\subcaptionbox{\emph{velocityz}}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/SIG-(GREEDY)-(laplacian)-velocityz.png}}
	\subcaptionbox{\emph{marschner-lobb}}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/SIG-(GREEDY)-(laplacian)-marschner-lobb.png}}
	\subcaptionbox{\emph{euler}}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/SIG-(GREEDY)-(laplacian)-euler.png}}
	\subcaptionbox{\emph{pressure}}
	{\includegraphics[width=0.48\linewidth]{img/laplacian/SIG-(GREEDY)-(laplacian)-pressure.png}}
	\caption{Precision map per subband (brigther is more precise) \emph{velocityz}, 1.28 bps. \emph{by wavelet norm} allocates more bits for the coarse-level subbands, while \emph{laplacian-optimized} and \emph{laplacian signature} do the opposite.}
	\label{fig:laplacian-precision-comparison}
\end{figure}

Using the signature for \emph{laplacian-optimized}, we are able construct a data-independent stream
(in the sense that once the signature is computed and is given, the ordering of the bits follows the
the signature only). This stream, called \emph{laplacian signature}, performs at least as well as,
and often better, than \emph{rmse-optimized} for all data sets (see Figure
\ref{fig:laplacian-comparison}). The reason \emph{laplacian signature} does not always outperform
\emph{rmse-optimized}, and that there is still a gap between itself and \emph{laplacian-optimized}
is that the signature is computed essentially by `'averaging'' local signatures, a process that
lessen the effectiveness of the signature when the data is highly inhomogenous (e.g., the euler data
set with its sharp shockwaves). Nevertheless, even with one signature for the whole domain, we are
able to reconstruct more accurate Laplacian in all cases in experiment. In practice, the signature
is a tiny piece of meta information that can be pre-computed, stored, and transmitted before any
value bits to help `'steer'' the data stream, whenever Laplacian is the quantity of interest.
